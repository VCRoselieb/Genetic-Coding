{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random start of population\n",
    "#genomes as a list of gene sequences\n",
    "def initialise():\n",
    "    genomes =[]\n",
    "    for i in range(2):\n",
    "        genomes.append([np.random.randint(2, size=6)]) # add 5 randomly initialised indiviudals\n",
    "    \n",
    "    return genomes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "\n",
    "def paring(mom,dad):\n",
    "    return(np.concatenate((mom[:3], dad[3:]), axis=0))\n",
    "\n",
    "def entschachteln(genos):\n",
    "    print(len(genos))\n",
    "    neue = [0,0]\n",
    "    i = 0\n",
    "    for k in genos:\n",
    "        for l in k:\n",
    "            print(l)\n",
    "            neue[i] =l\n",
    "            i = i+1\n",
    "\n",
    "    return (neue)\n",
    "\n",
    "def mutation(popul):\n",
    "    position = random.randrange(0, len(popul))\n",
    "    gencode = popul[position]\n",
    "    \n",
    "    decider = random.uniform(0, 1)\n",
    "    posi = 0\n",
    "    if decider < 0.2 :\n",
    "        print('Mutation')\n",
    "        posi = random.randrange(0, len(gencode))\n",
    "    \n",
    "        if gencode[posi] == 1:\n",
    "            gencode[posi] = 0\n",
    "        elif gencode[posi] == 0:\n",
    "            gencode[posi] = 1\n",
    "            \n",
    "    popul[position] = np.array(gencode)\n",
    "    \n",
    "    return popul\n",
    "\n",
    "\n",
    "def selected(maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-2:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "   \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "            \n",
    "   \n",
    "    \n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netzdurchlauf(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "        batch_size = 128\n",
    "        num_classes = 10\n",
    "        epochs = 12\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "        for gen in element:\n",
    "            if (gen== 0):\n",
    "                model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            elif (gen == 1):\n",
    "                model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hauptmethode\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DURCHGÄNGE = 2 # variable to clarify number of generations\n",
    "actualpop= initialise()\n",
    "actualpop= entschachteln(actualpop)\n",
    "evalaccuris = []\n",
    "saved = actualpop\n",
    "i = 1\n",
    "    \n",
    "while i < DURCHGÄNGE:\n",
    "    \n",
    "    nummer = i\n",
    "    accuri = netzdurchlauf(actualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(accuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(accuri))\n",
    "    print(actualpop)\n",
    "#     actualpop = selected(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "    \n",
    "    evalaccuris.append([i ,np.amax(accuri)])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The highest accuracies in population')\n",
    "print(evalaccuris)  \n",
    "\n",
    "print('Wartezeit: ')\n",
    "end = time.time()\n",
    "seconds = end - start\n",
    "minutes = seconds / 60\n",
    "print(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[1 0 1 1 0 0]\n",
      "[1 0 0 1 1 1]\n",
      "Aktuelle Population\n",
      "[array([1, 0, 1, 1, 0, 0]), array([1, 0, 0, 1, 1, 1])]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.2921 - acc: 0.9075 - val_loss: 0.0594 - val_acc: 0.9824\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0761 - acc: 0.9769 - val_loss: 0.0420 - val_acc: 0.9861\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0542 - acc: 0.9834 - val_loss: 0.0316 - val_acc: 0.9895\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0431 - acc: 0.9859 - val_loss: 0.0279 - val_acc: 0.9909\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.0237 - val_acc: 0.9915\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0309 - acc: 0.9906 - val_loss: 0.0217 - val_acc: 0.9927\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0275 - acc: 0.9911 - val_loss: 0.0251 - val_acc: 0.9921\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0250 - acc: 0.9921 - val_loss: 0.0204 - val_acc: 0.9933\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0221 - acc: 0.9929 - val_loss: 0.0208 - val_acc: 0.9938\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0209 - val_acc: 0.9933\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0186 - val_acc: 0.9940\n",
      "Test loss: 0.018609789634769912\n",
      "Test accuracy: 0.994\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.2887 - acc: 0.9086 - val_loss: 0.0631 - val_acc: 0.9799\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0747 - acc: 0.9770 - val_loss: 0.0347 - val_acc: 0.9884\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0542 - acc: 0.9835 - val_loss: 0.0306 - val_acc: 0.9898\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0424 - acc: 0.9871 - val_loss: 0.0287 - val_acc: 0.9896\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0373 - acc: 0.9882 - val_loss: 0.0340 - val_acc: 0.9883\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0320 - acc: 0.9903 - val_loss: 0.0255 - val_acc: 0.9918\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0286 - acc: 0.9908 - val_loss: 0.0261 - val_acc: 0.9909\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0259 - acc: 0.9923 - val_loss: 0.0228 - val_acc: 0.9924\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0197 - acc: 0.9940 - val_loss: 0.0238 - val_acc: 0.9933\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0213 - val_acc: 0.9931\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0222 - val_acc: 0.9936\n",
      "Test loss: 0.022178589758985255\n",
      "Test accuracy: 0.9936\n",
      " Accuracy of populationnummer: \n",
      "0\n",
      "[0.994, 0.9936]\n",
      "highest accuracy of populationnummer: \n",
      "0\n",
      "0.994\n",
      "[array([1, 0, 1, 1, 0, 0]), array([1, 0, 0, 1, 1, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "Aktuelle Population\n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 1, 1, 1, 1])]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.3686 - acc: 0.8828 - val_loss: 0.0673 - val_acc: 0.9795\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0782 - acc: 0.9763 - val_loss: 0.0377 - val_acc: 0.9880\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0526 - acc: 0.9840 - val_loss: 0.0405 - val_acc: 0.9870\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0408 - acc: 0.9876 - val_loss: 0.0219 - val_acc: 0.9928\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0335 - acc: 0.9896 - val_loss: 0.0231 - val_acc: 0.9928\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0285 - acc: 0.9913 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0255 - val_acc: 0.9918\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0218 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0194 - val_acc: 0.9940\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0175 - acc: 0.9945 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0169 - acc: 0.9950 - val_loss: 0.0176 - val_acc: 0.9941\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0231 - val_acc: 0.9933\n",
      "Test loss: 0.023131916773996453\n",
      "Test accuracy: 0.9933\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.2877 - acc: 0.9112 - val_loss: 0.0605 - val_acc: 0.9797\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0737 - acc: 0.9780 - val_loss: 0.0698 - val_acc: 0.9787\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.0535 - acc: 0.9842 - val_loss: 0.0359 - val_acc: 0.9877\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0439 - acc: 0.9866 - val_loss: 0.0320 - val_acc: 0.9894\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0377 - acc: 0.9878 - val_loss: 0.0286 - val_acc: 0.9898\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0346 - acc: 0.9891 - val_loss: 0.0247 - val_acc: 0.9921\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.0300 - acc: 0.9908 - val_loss: 0.0308 - val_acc: 0.9893\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0271 - acc: 0.9915 - val_loss: 0.0315 - val_acc: 0.9900\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0245 - acc: 0.9925 - val_loss: 0.0263 - val_acc: 0.9906\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0310 - val_acc: 0.9900\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0272 - val_acc: 0.9914\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 0.0260 - val_acc: 0.9923\n",
      "Test loss: 0.025983707956981742\n",
      "Test accuracy: 0.9923\n",
      " Accuracy of populationnummer: \n",
      "1\n",
      "[0.9933, 0.9923]\n",
      "highest accuracy of populationnummer: \n",
      "1\n",
      "0.9933\n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 1, 1, 1, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "Mutation\n",
      "The highest accuracies in population\n",
      "[[1, 0.994], [2, 0.9933]]\n",
      "Wartezeit: \n",
      "624.2815301418304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(data =evalaccuris)\n",
    "df.rename(columns={0: 'Generation',1:'Accuracy'}, inplace=True)\n",
    "df\n",
    "sns.regplot(x=df['Generation'],y=df['Accuracy'])\n",
    "plt.ylim(0.990, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([1, 1, 1, 0, 0, 1])], [array([1, 1, 1, 1, 1, 0])]]\n",
      "2\n",
      "[1 1 1 0 0 1]\n",
      "[1 1 1 1 1 0]\n",
      "[array([1, 1, 1, 0, 0, 1]), array([1, 1, 1, 1, 1, 0])]\n",
      "Aktuelle Population\n",
      "[[array([1, 1, 1, 0, 0, 1])], [array([1, 1, 1, 1, 1, 0])]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.2626 - acc: 0.9188 - val_loss: 0.0616 - val_acc: 0.9819\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.0704 - acc: 0.9784 - val_loss: 0.0406 - val_acc: 0.9870\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0522 - acc: 0.9842 - val_loss: 0.0317 - val_acc: 0.9887\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0422 - acc: 0.9870 - val_loss: 0.0353 - val_acc: 0.9884\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0356 - acc: 0.9894 - val_loss: 0.0274 - val_acc: 0.9911\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0295 - val_acc: 0.9895\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0273 - acc: 0.9913 - val_loss: 0.0301 - val_acc: 0.9902\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0249 - acc: 0.9922 - val_loss: 0.0246 - val_acc: 0.9914\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.0219 - val_acc: 0.9929\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0238 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0176 - acc: 0.9946 - val_loss: 0.0229 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0162 - acc: 0.9949 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Test loss: 0.02456088453789125\n",
      "Test accuracy: 0.992\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.2740 - acc: 0.9145 - val_loss: 0.0837 - val_acc: 0.9749\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0924 - acc: 0.9725 - val_loss: 0.0488 - val_acc: 0.9836\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0703 - acc: 0.9786 - val_loss: 0.0414 - val_acc: 0.9860\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0594 - acc: 0.9820 - val_loss: 0.0391 - val_acc: 0.9870\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0522 - acc: 0.9839 - val_loss: 0.0346 - val_acc: 0.9881\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0465 - acc: 0.9857 - val_loss: 0.0344 - val_acc: 0.9885\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0430 - acc: 0.9867 - val_loss: 0.0340 - val_acc: 0.9886\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0405 - acc: 0.9874 - val_loss: 0.0305 - val_acc: 0.9892\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0322 - val_acc: 0.9892\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0337 - acc: 0.9895 - val_loss: 0.0319 - val_acc: 0.9888\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0325 - acc: 0.9901 - val_loss: 0.0284 - val_acc: 0.9897\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.0281 - val_acc: 0.9910\n",
      "Test loss: 0.028114998727181227\n",
      "Test accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fix schachtelung\n",
    "\n",
    "def entschachteln(genos):\n",
    "    print(len(genos))\n",
    "    neue = [0,0]\n",
    "    i = 0\n",
    "    for k in genos:\n",
    "        for l in k:\n",
    "            print(l)\n",
    "            neue[i] =l\n",
    "            i = i+1\n",
    "\n",
    "    return (neue)\n",
    "    \n",
    "\n",
    "actualpop= initialise()\n",
    "print(actualpop)\n",
    "neue = entschachteln(actualpop)\n",
    "print(neue)\n",
    "\n",
    "acc = netzdurchlauf1(neue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest acc at\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "actualpop = selected2(acc, neue)\n",
    "actualpop = mutation(actualpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
