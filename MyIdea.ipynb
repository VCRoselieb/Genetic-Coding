{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random start of population\n",
    "#genomes as a list of gene sequences\n",
    "def initialise():\n",
    "    genomes =[]\n",
    "    for i in range(4):\n",
    "        genomes.append([np.random.randint(2, size=6)]) # add 5 randomly initialised indiviudals\n",
    "    \n",
    "    #entschachtelungsprozess\n",
    "    ent = [5]*len(genomes)\n",
    "    i = 0\n",
    "    for k in genomes:\n",
    "        for l in k:\n",
    "            \n",
    "            ent[i] =l\n",
    "            i = i+1\n",
    "    \n",
    "\n",
    "    return ent\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "\n",
    "def paring(mom,dad):\n",
    "    return(np.concatenate((mom[:3], dad[3:]), axis=0))\n",
    "\n",
    "def entschachteln(genos):\n",
    "    print(len(genos))\n",
    "    neue = [0,0]\n",
    "    i = 0\n",
    "    for k in genos:\n",
    "        for l in k:\n",
    "            print(l)\n",
    "            neue[i] =l\n",
    "            i = i+1\n",
    "\n",
    "    return (neue)\n",
    "\n",
    "def mutation(popul):\n",
    "    position = random.randrange(0, len(popul))\n",
    "    gencode = popul[position]\n",
    "    \n",
    "    decider = random.uniform(0, 1)\n",
    "    posi = 0\n",
    "    if decider < 0.1 :\n",
    "        print('Mutation')\n",
    "        posi = random.randrange(0, len(gencode))\n",
    "    \n",
    "        if gencode[posi] == 1:\n",
    "            gencode[posi] = 0\n",
    "        elif gencode[posi] == 0:\n",
    "            gencode[posi] = 1\n",
    "            \n",
    "    popul[position] = np.array(gencode)\n",
    "    \n",
    "    return popul\n",
    "\n",
    "''' A one to one replacement reproduction '''\n",
    "def selected(maxis, actualpop): \n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-4:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "   \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "            \n",
    "    print('PPPPPP')\n",
    "    print(parents)\n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    print(parents)\n",
    "    \n",
    "    #### was passiert ungerade zahl geht nicht und 50 eltern überleben\n",
    "    # 1 un2 2un3\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netzdurchlauf(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "        batch_size = 128\n",
    "        num_classes = 10\n",
    "        epochs = 12\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "        for gen in element:\n",
    "            if (gen== 0):\n",
    "                model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            elif (gen == 1):\n",
    "                model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fortpflanzung (maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-2:][::-1] # hier verändern, wenn wir individuen anzahl erhöhen die erste zahl muss die hälfte der anzahl sein\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "    \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "   \n",
    "    \n",
    "    print('PPPPPP')\n",
    "    print(parents)\n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    print(parents)\n",
    "    #parents = entschachteln(parents)\n",
    "    \n",
    "    while f < len(parents): \n",
    "        print(f)\n",
    "        f = f -1\n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        print(f)\n",
    "        dad = parents[f]    \n",
    "        f= f +1\n",
    "        decider = random.uniform(0, 1) # decides random how the cross-over works\n",
    "        if decider < 0.5 :\n",
    "            child = paring(mom,dad)\n",
    "            childs.append(child)\n",
    "        else:\n",
    "            child = paring(dad,mom)\n",
    "            childs.append(child)\n",
    "\n",
    "    \n",
    "#         child = paring(mom,dad)\n",
    "#         childs.append(child)\n",
    "    \n",
    "#             child = paring(dad,mom)\n",
    "#             childs.append(child)\n",
    "\n",
    "#     while f < len(parents)-1: \n",
    "#         mom = parents[f]\n",
    "#         f= f +1\n",
    "#         dad = parents[f]     \n",
    "#         child = paring(mom,dad)\n",
    "#         childs.append(child)\n",
    "#         child = paring(dad,mom)\n",
    "#         childs.append(child)\n",
    "    print('CCCCCCC')\n",
    "    print(childs)\n",
    "    parents = np.concatenate((parents, childs), axis=0) \n",
    "    \n",
    "    print('OVERALL')\n",
    "    print(parents)\n",
    "    print(len(parents))\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelle Population\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0]), array([1, 1, 0, 0, 0, 0]), array([1, 0, 1, 0, 1, 1])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0920 13:37:51.609639 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0920 13:37:51.622620 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0920 13:37:51.624612 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0920 13:37:51.651532 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0920 13:37:51.654522 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0920 13:37:51.661501 15840 deprecation.py:506] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0920 13:37:51.794159 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0920 13:37:51.801126 15840 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0920 13:37:51.951725 15840 deprecation.py:323] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.3783 - acc: 0.8774 - val_loss: 0.0672 - val_acc: 0.9768\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0700 - acc: 0.9788 - val_loss: 0.0448 - val_acc: 0.9861\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0470 - acc: 0.9851 - val_loss: 0.0362 - val_acc: 0.9879\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0367 - acc: 0.9885 - val_loss: 0.0267 - val_acc: 0.9923\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0291 - acc: 0.9909 - val_loss: 0.0194 - val_acc: 0.9942\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0194 - val_acc: 0.9946\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0214 - val_acc: 0.9933\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0198 - val_acc: 0.9947\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0138 - acc: 0.9958 - val_loss: 0.0256 - val_acc: 0.9924\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0184 - val_acc: 0.9946\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0113 - acc: 0.9965 - val_loss: 0.0240 - val_acc: 0.9937\n",
      "Test loss: 0.023965450994987623\n",
      "Test accuracy: 0.9937\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3840 - acc: 0.8762 - val_loss: 0.0558 - val_acc: 0.9815\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0669 - val_acc: 0.9779\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0541 - acc: 0.9831 - val_loss: 0.0278 - val_acc: 0.9901\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0411 - acc: 0.9876 - val_loss: 0.0237 - val_acc: 0.9919\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0343 - acc: 0.9899 - val_loss: 0.0340 - val_acc: 0.9902\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0229 - val_acc: 0.9929\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0257 - acc: 0.9922 - val_loss: 0.0242 - val_acc: 0.9928\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0233 - acc: 0.9928 - val_loss: 0.0189 - val_acc: 0.9935\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0230 - val_acc: 0.9927\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0166 - val_acc: 0.9948\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.0195 - val_acc: 0.9940\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0153 - acc: 0.9955 - val_loss: 0.0186 - val_acc: 0.9948\n",
      "Test loss: 0.01859946153665478\n",
      "Test accuracy: 0.9948\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.3512 - acc: 0.8879 - val_loss: 0.0889 - val_acc: 0.9703\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0788 - acc: 0.9760 - val_loss: 0.0334 - val_acc: 0.9892\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0519 - acc: 0.9843 - val_loss: 0.0309 - val_acc: 0.9905\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0397 - acc: 0.9879 - val_loss: 0.0299 - val_acc: 0.9904\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0331 - acc: 0.9901 - val_loss: 0.0225 - val_acc: 0.9929\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0272 - acc: 0.9916 - val_loss: 0.0213 - val_acc: 0.9934\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0222 - val_acc: 0.9934\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0284 - val_acc: 0.9917\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0200 - acc: 0.9935 - val_loss: 0.0215 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0172 - acc: 0.9943 - val_loss: 0.0235 - val_acc: 0.9931\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0145 - acc: 0.9954 - val_loss: 0.0211 - val_acc: 0.9934\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0231 - val_acc: 0.9931\n",
      "Test loss: 0.023105697293815137\n",
      "Test accuracy: 0.9931\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.2684 - acc: 0.9161 - val_loss: 0.0746 - val_acc: 0.9775\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0708 - acc: 0.9787 - val_loss: 0.0437 - val_acc: 0.9848\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0521 - acc: 0.9838 - val_loss: 0.0322 - val_acc: 0.9893\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0352 - acc: 0.9888 - val_loss: 0.0276 - val_acc: 0.9905\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0322 - acc: 0.9899 - val_loss: 0.0290 - val_acc: 0.9902\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0277 - acc: 0.9913 - val_loss: 0.0248 - val_acc: 0.9912\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0244 - val_acc: 0.9916\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0228 - acc: 0.9924 - val_loss: 0.0230 - val_acc: 0.9930\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0245 - val_acc: 0.9925\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0175 - acc: 0.9945 - val_loss: 0.0211 - val_acc: 0.9933\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0210 - val_acc: 0.9930\n",
      "Test loss: 0.020977800093947008\n",
      "Test accuracy: 0.993\n",
      " Accuracy of populationnummer: \n",
      "1\n",
      "[0.9937, 0.9948, 0.9931, 0.993]\n",
      "highest accuracy of populationnummer: \n",
      "1\n",
      "0.9948\n",
      "Highest acc at\n",
      "[1 0]\n",
      "PPPPPP\n",
      "[array([0, 0, 0, 1, 1, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0])]\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "CCCCCCC\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0])]\n",
      "OVERALL\n",
      "[[0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]]\n",
      "4\n",
      "Aktuelle Population\n",
      "[[0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.3761 - acc: 0.8770 - val_loss: 0.0489 - val_acc: 0.9844\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0746 - acc: 0.9778 - val_loss: 0.0570 - val_acc: 0.9828\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0504 - acc: 0.9847 - val_loss: 0.0305 - val_acc: 0.9900\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0391 - acc: 0.9879 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0310 - acc: 0.9908 - val_loss: 0.0261 - val_acc: 0.9910\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0268 - acc: 0.9914 - val_loss: 0.0265 - val_acc: 0.9920\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0226 - acc: 0.9930 - val_loss: 0.0204 - val_acc: 0.9934\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0300 - val_acc: 0.9915\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0251 - val_acc: 0.9915\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0210 - val_acc: 0.9931\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0233 - val_acc: 0.9932\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0217 - val_acc: 0.9936\n",
      "Test loss: 0.021683169538700715\n",
      "Test accuracy: 0.9936\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3797 - acc: 0.8749 - val_loss: 0.0872 - val_acc: 0.9726\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0814 - acc: 0.9754 - val_loss: 0.0443 - val_acc: 0.9870\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0530 - acc: 0.9838 - val_loss: 0.0392 - val_acc: 0.9885\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0412 - acc: 0.9873 - val_loss: 0.0266 - val_acc: 0.9918\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0353 - acc: 0.9893 - val_loss: 0.0219 - val_acc: 0.9936\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0228 - val_acc: 0.9928\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0260 - acc: 0.9922 - val_loss: 0.0243 - val_acc: 0.9921\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0230 - acc: 0.9933 - val_loss: 0.0235 - val_acc: 0.9929\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0203 - val_acc: 0.9941\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0188 - val_acc: 0.9939\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0223 - val_acc: 0.9934\n",
      "Test loss: 0.022315948965215285\n",
      "Test accuracy: 0.9934\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.3794 - acc: 0.8775 - val_loss: 0.0846 - val_acc: 0.9729\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0743 - acc: 0.9774 - val_loss: 0.0339 - val_acc: 0.9894\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0491 - acc: 0.9851 - val_loss: 0.0310 - val_acc: 0.9900\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.0289 - val_acc: 0.9909\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.0233 - val_acc: 0.9928\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0267 - acc: 0.9916 - val_loss: 0.0279 - val_acc: 0.9910: 0s - loss: 0.0271 - acc: \n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0233 - val_acc: 0.9925\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0228 - val_acc: 0.9929\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0178 - acc: 0.9946 - val_loss: 0.0211 - val_acc: 0.9924\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0224 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0207 - val_acc: 0.9942\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0255 - val_acc: 0.9928\n",
      "Test loss: 0.025501387057331886\n",
      "Test accuracy: 0.9928\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3668 - acc: 0.8822 - val_loss: 0.0736 - val_acc: 0.9785\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0850 - acc: 0.9746 - val_loss: 0.0332 - val_acc: 0.9888\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0556 - acc: 0.9835 - val_loss: 0.0410 - val_acc: 0.9867\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0408 - acc: 0.9877 - val_loss: 0.0293 - val_acc: 0.9903\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0361 - acc: 0.9883 - val_loss: 0.0230 - val_acc: 0.9926\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0299 - acc: 0.9910 - val_loss: 0.0223 - val_acc: 0.9925\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0259 - acc: 0.9921 - val_loss: 0.0240 - val_acc: 0.9923\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0217 - acc: 0.9930 - val_loss: 0.0197 - val_acc: 0.9938\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0177 - acc: 0.9946 - val_loss: 0.0209 - val_acc: 0.9933\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0200 - val_acc: 0.9936\n",
      "Test loss: 0.020003335939691533\n",
      "Test accuracy: 0.9936\n",
      " Accuracy of populationnummer: \n",
      "2\n",
      "[0.9936, 0.9934, 0.9928, 0.9936]\n",
      "highest accuracy of populationnummer: \n",
      "2\n",
      "0.9936\n",
      "Highest acc at\n",
      "[3 0]\n",
      "PPPPPP\n",
      "[array([0, 0, 0, 1, 1, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0])]\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "CCCCCCC\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0])]\n",
      "OVERALL\n",
      "[[0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]]\n",
      "4\n",
      "Aktuelle Population\n",
      "[[0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.3732 - acc: 0.8790 - val_loss: 0.0992 - val_acc: 0.9706\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0731 - acc: 0.9777 - val_loss: 0.0391 - val_acc: 0.9872\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0490 - acc: 0.9852 - val_loss: 0.0260 - val_acc: 0.9918\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0384 - acc: 0.9877 - val_loss: 0.0247 - val_acc: 0.9923\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0288 - val_acc: 0.9912\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0265 - acc: 0.9921 - val_loss: 0.0239 - val_acc: 0.9924\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.0254 - val_acc: 0.9924\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0173 - acc: 0.9948 - val_loss: 0.0211 - val_acc: 0.9931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0204 - val_acc: 0.9944\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0321 - val_acc: 0.9914\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0121 - acc: 0.9962 - val_loss: 0.0181 - val_acc: 0.9946\n",
      "Test loss: 0.018118250372678814\n",
      "Test accuracy: 0.9946\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.3813 - acc: 0.8764 - val_loss: 0.0664 - val_acc: 0.9785\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0838 - acc: 0.9744 - val_loss: 0.0485 - val_acc: 0.9857\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0556 - acc: 0.9833 - val_loss: 0.0323 - val_acc: 0.9895\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0420 - acc: 0.9871 - val_loss: 0.0273 - val_acc: 0.9908\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0346 - acc: 0.9896 - val_loss: 0.0246 - val_acc: 0.9926\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0296 - acc: 0.9908 - val_loss: 0.0212 - val_acc: 0.9936\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0215 - val_acc: 0.9941\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0224 - acc: 0.9934 - val_loss: 0.0216 - val_acc: 0.9935\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0200 - acc: 0.9938 - val_loss: 0.0197 - val_acc: 0.9938\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0237 - val_acc: 0.9922\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0223 - val_acc: 0.9940\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0199 - val_acc: 0.9940\n",
      "Test loss: 0.019899739505693834\n",
      "Test accuracy: 0.994\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3820 - acc: 0.8773 - val_loss: 0.0647 - val_acc: 0.9790\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0741 - acc: 0.9772 - val_loss: 0.0412 - val_acc: 0.9874\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0488 - acc: 0.9851 - val_loss: 0.0259 - val_acc: 0.9913\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0370 - acc: 0.9889 - val_loss: 0.0272 - val_acc: 0.9913\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0314 - acc: 0.9906 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0219 - val_acc: 0.9937\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0223 - acc: 0.9932 - val_loss: 0.0304 - val_acc: 0.9905\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0229 - val_acc: 0.9932\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0156 - acc: 0.9949 - val_loss: 0.0178 - val_acc: 0.9947\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0210 - val_acc: 0.9936\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0141 - acc: 0.9958 - val_loss: 0.0240 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.0231 - val_acc: 0.9936\n",
      "Test loss: 0.023050021302065987\n",
      "Test accuracy: 0.9936\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.3862 - acc: 0.8740 - val_loss: 0.0622 - val_acc: 0.9789\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0835 - acc: 0.9740 - val_loss: 0.0428 - val_acc: 0.9855\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0555 - acc: 0.9826 - val_loss: 0.0303 - val_acc: 0.9908\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0259 - val_acc: 0.9921\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0354 - acc: 0.9886 - val_loss: 0.0237 - val_acc: 0.9930\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0299 - acc: 0.9911 - val_loss: 0.0255 - val_acc: 0.9915\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0258 - acc: 0.9916 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0209 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0201 - val_acc: 0.9945\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0243 - val_acc: 0.9937\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.0207 - val_acc: 0.9938\n",
      "Test loss: 0.020681277607477386\n",
      "Test accuracy: 0.9938\n",
      " Accuracy of populationnummer: \n",
      "3\n",
      "[0.9946, 0.994, 0.9936, 0.9938]\n",
      "highest accuracy of populationnummer: \n",
      "3\n",
      "0.9946\n",
      "Highest acc at\n",
      "[0 1]\n",
      "PPPPPP\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0])]\n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 1, 1, 0])]\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "CCCCCCC\n",
      "[array([0, 0, 0, 1, 1, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "OVERALL\n",
      "[[0 0 0 0 1 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]]\n",
      "4\n",
      "Mutation\n",
      "Aktuelle Population\n",
      "[[0 0 0 0 1 1]\n",
      " [1 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.3617 - acc: 0.8827 - val_loss: 0.0628 - val_acc: 0.9795\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0751 - acc: 0.9770 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0499 - acc: 0.9853 - val_loss: 0.0363 - val_acc: 0.9874\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0386 - acc: 0.9884 - val_loss: 0.0309 - val_acc: 0.9910\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0312 - acc: 0.9908 - val_loss: 0.0261 - val_acc: 0.9914\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0264 - acc: 0.9916 - val_loss: 0.0221 - val_acc: 0.9923\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0258 - val_acc: 0.9917\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0198 - acc: 0.9939 - val_loss: 0.0151 - val_acc: 0.9946\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0172 - acc: 0.9950 - val_loss: 0.0177 - val_acc: 0.9951\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0188 - val_acc: 0.9947\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0198 - val_acc: 0.9943\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0208 - val_acc: 0.9939\n",
      "Test loss: 0.020835834155037675\n",
      "Test accuracy: 0.9939\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.3229 - acc: 0.8975 - val_loss: 0.0593 - val_acc: 0.9820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0813 - acc: 0.9749 - val_loss: 0.0413 - val_acc: 0.9856\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0549 - acc: 0.9830 - val_loss: 0.0317 - val_acc: 0.9895\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0442 - acc: 0.9864 - val_loss: 0.0422 - val_acc: 0.9871\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0380 - acc: 0.9880 - val_loss: 0.0266 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0328 - acc: 0.9899 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0279 - acc: 0.9912 - val_loss: 0.0207 - val_acc: 0.9930\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0209 - val_acc: 0.9937\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0198 - val_acc: 0.9937\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0245 - val_acc: 0.9922\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0209 - val_acc: 0.9929\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0199 - val_acc: 0.9938\n",
      "Test loss: 0.019873646203335375\n",
      "Test accuracy: 0.9938\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.3871 - acc: 0.8744 - val_loss: 0.0789 - val_acc: 0.9766\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0806 - acc: 0.9754 - val_loss: 0.0319 - val_acc: 0.9910\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0537 - acc: 0.9840 - val_loss: 0.0289 - val_acc: 0.9910\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0415 - acc: 0.9873 - val_loss: 0.0282 - val_acc: 0.9918\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0343 - acc: 0.9896 - val_loss: 0.0285 - val_acc: 0.9913\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0305 - acc: 0.9908 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0244 - acc: 0.9924 - val_loss: 0.0233 - val_acc: 0.9925\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0238 - acc: 0.9927 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0198 - val_acc: 0.9935\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0185 - acc: 0.9944 - val_loss: 0.0301 - val_acc: 0.9906\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0172 - acc: 0.9942 - val_loss: 0.0208 - val_acc: 0.9928\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0225 - val_acc: 0.9934\n",
      "Test loss: 0.022509214642799272\n",
      "Test accuracy: 0.9934\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.3405 - acc: 0.8911 - val_loss: 0.0705 - val_acc: 0.9761\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0715 - acc: 0.9779 - val_loss: 0.0377 - val_acc: 0.9872\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0496 - acc: 0.9845 - val_loss: 0.0273 - val_acc: 0.9919\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0383 - acc: 0.9885 - val_loss: 0.0322 - val_acc: 0.9905\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0310 - acc: 0.9904 - val_loss: 0.0480 - val_acc: 0.9851\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0268 - acc: 0.9923 - val_loss: 0.0255 - val_acc: 0.9920\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0217 - acc: 0.9936 - val_loss: 0.0208 - val_acc: 0.9937\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0204 - acc: 0.9938 - val_loss: 0.0216 - val_acc: 0.9933\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0225 - val_acc: 0.9928\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0156 - acc: 0.9953 - val_loss: 0.0208 - val_acc: 0.9934\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0255 - val_acc: 0.9930\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0259 - val_acc: 0.9931\n",
      "Test loss: 0.025851921410293882\n",
      "Test accuracy: 0.9931\n",
      " Accuracy of populationnummer: \n",
      "4\n",
      "[0.9939, 0.9938, 0.9934, 0.9931]\n",
      "highest accuracy of populationnummer: \n",
      "4\n",
      "0.9939\n",
      "Highest acc at\n",
      "[0 1]\n",
      "PPPPPP\n",
      "[array([0, 0, 0, 0, 1, 1]), array([1, 0, 0, 1, 1, 0])]\n",
      "[array([0, 0, 0, 0, 1, 1]), array([1, 0, 0, 1, 1, 0])]\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "CCCCCCC\n",
      "[array([0, 0, 0, 1, 1, 0]), array([0, 0, 0, 1, 1, 0])]\n",
      "OVERALL\n",
      "[[0 0 0 0 1 1]\n",
      " [1 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]]\n",
      "4\n",
      "Aktuelle Population\n",
      "[[0 0 0 0 1 1]\n",
      " [1 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.3610 - acc: 0.8824 - val_loss: 0.0642 - val_acc: 0.9791\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0699 - acc: 0.9782 - val_loss: 0.0498 - val_acc: 0.9844\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0489 - acc: 0.9849 - val_loss: 0.0359 - val_acc: 0.9880\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0364 - acc: 0.9889 - val_loss: 0.0306 - val_acc: 0.9899\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0237 - val_acc: 0.9930\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0313 - val_acc: 0.9915\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0214 - val_acc: 0.9935\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0186 - val_acc: 0.9944\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0229 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0137 - acc: 0.9960 - val_loss: 0.0254 - val_acc: 0.9918\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0278 - val_acc: 0.9924\n",
      "Test loss: 0.027822042082847293\n",
      "Test accuracy: 0.9924\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.3251 - acc: 0.8968 - val_loss: 0.0723 - val_acc: 0.9813\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0752 - acc: 0.9770 - val_loss: 0.0523 - val_acc: 0.9849\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 1412s 24ms/step - loss: 0.0519 - acc: 0.9843 - val_loss: 0.0307 - val_acc: 0.9895\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0409 - acc: 0.9874 - val_loss: 0.0266 - val_acc: 0.9917\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0341 - acc: 0.9891 - val_loss: 0.0252 - val_acc: 0.9917\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0248 - val_acc: 0.9918\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0254 - acc: 0.9921 - val_loss: 0.0206 - val_acc: 0.9932\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0238 - val_acc: 0.9917\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0203 - val_acc: 0.9944\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Test loss: 0.02045985019147738\n",
      "Test accuracy: 0.9932\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.4099 - acc: 0.8660 - val_loss: 0.0617 - val_acc: 0.9800\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0781 - acc: 0.9766 - val_loss: 0.0387 - val_acc: 0.9876\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0528 - acc: 0.9845 - val_loss: 0.0286 - val_acc: 0.9915\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0402 - acc: 0.9877 - val_loss: 0.0316 - val_acc: 0.9894\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0339 - acc: 0.9893 - val_loss: 0.0351 - val_acc: 0.9885\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0283 - acc: 0.9912 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0295 - val_acc: 0.9899\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0229 - acc: 0.9928 - val_loss: 0.0258 - val_acc: 0.9910\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0203 - acc: 0.9933 - val_loss: 0.0236 - val_acc: 0.9919\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.0234 - val_acc: 0.9927\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0207 - val_acc: 0.9942\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0150 - acc: 0.9953 - val_loss: 0.0240 - val_acc: 0.9934\n",
      "Test loss: 0.024002524685627122\n",
      "Test accuracy: 0.9934\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.3801 - acc: 0.8768 - val_loss: 0.0706 - val_acc: 0.9790\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0853 - acc: 0.9739 - val_loss: 0.0387 - val_acc: 0.9883\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0553 - acc: 0.9833 - val_loss: 0.0426 - val_acc: 0.9864\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0424 - acc: 0.9867 - val_loss: 0.0292 - val_acc: 0.9902\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0271 - val_acc: 0.9898\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0233 - val_acc: 0.9927\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0190 - val_acc: 0.9938\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0207 - acc: 0.9940 - val_loss: 0.0234 - val_acc: 0.9930\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0178 - acc: 0.9944 - val_loss: 0.0196 - val_acc: 0.9938\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0206 - val_acc: 0.9941\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0259 - val_acc: 0.9916\n",
      "Test loss: 0.025932101580147717\n",
      "Test accuracy: 0.9916\n",
      " Accuracy of populationnummer: \n",
      "5\n",
      "[0.9924, 0.9932, 0.9934, 0.9916]\n",
      "highest accuracy of populationnummer: \n",
      "5\n",
      "0.9934\n",
      "Highest acc at\n",
      "[2 1]\n",
      "PPPPPP\n",
      "[array([0, 0, 0, 1, 1, 0]), array([1, 0, 0, 1, 1, 0])]\n",
      "[array([0, 0, 0, 1, 1, 0]), array([1, 0, 0, 1, 1, 0])]\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "CCCCCCC\n",
      "[array([1, 0, 0, 1, 1, 0]), array([0, 0, 0, 1, 1, 0])]\n",
      "OVERALL\n",
      "[[0 0 0 1 1 0]\n",
      " [1 0 0 1 1 0]\n",
      " [1 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]]\n",
      "4\n",
      "Aktuelle Population\n",
      "[[0 0 0 1 1 0]\n",
      " [1 0 0 1 1 0]\n",
      " [1 0 0 1 1 0]\n",
      " [0 0 0 1 1 0]]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.3658 - acc: 0.8803 - val_loss: 0.0800 - val_acc: 0.9748\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0419 - val_acc: 0.9875\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0560 - acc: 0.9827 - val_loss: 0.0329 - val_acc: 0.9891\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0420 - acc: 0.9872 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0341 - acc: 0.9898 - val_loss: 0.0255 - val_acc: 0.9921\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0305 - acc: 0.9905 - val_loss: 0.0278 - val_acc: 0.9910\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.0214 - val_acc: 0.9935\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0256 - val_acc: 0.9932\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 0.0234 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0206 - val_acc: 0.9939\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0313 - val_acc: 0.9896\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0248 - val_acc: 0.9934\n",
      "Test loss: 0.024770608936611097\n",
      "Test accuracy: 0.9934\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.3224 - acc: 0.8983 - val_loss: 0.0666 - val_acc: 0.9778\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0788 - acc: 0.9761 - val_loss: 0.0461 - val_acc: 0.9852\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0554 - acc: 0.9827 - val_loss: 0.0349 - val_acc: 0.9886\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0446 - acc: 0.9862 - val_loss: 0.0267 - val_acc: 0.9910\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0375 - acc: 0.9884 - val_loss: 0.0227 - val_acc: 0.9931\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0339 - acc: 0.9889 - val_loss: 0.0197 - val_acc: 0.9937\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.0188 - val_acc: 0.9935\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0210 - val_acc: 0.9935\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0233 - acc: 0.9926 - val_loss: 0.0192 - val_acc: 0.9940\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0203 - val_acc: 0.9936\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0217 - val_acc: 0.9929\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0226 - val_acc: 0.9937\n",
      "Test loss: 0.02262539964258831\n",
      "Test accuracy: 0.9937\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.3223 - acc: 0.8986 - val_loss: 0.0636 - val_acc: 0.9803\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0815 - acc: 0.9752 - val_loss: 0.0424 - val_acc: 0.9855\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0566 - acc: 0.9824 - val_loss: 0.0324 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0440 - acc: 0.9861 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0361 - acc: 0.9890 - val_loss: 0.0249 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0308 - acc: 0.9905 - val_loss: 0.0281 - val_acc: 0.9912\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0283 - acc: 0.9907 - val_loss: 0.0236 - val_acc: 0.9930\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0198 - val_acc: 0.9936\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0224 - acc: 0.9930 - val_loss: 0.0206 - val_acc: 0.9936\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0198 - val_acc: 0.9944\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0199 - val_acc: 0.9944\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0217 - val_acc: 0.9930\n",
      "Test loss: 0.0217156762487386\n",
      "Test accuracy: 0.993\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.3704 - acc: 0.8802 - val_loss: 0.0630 - val_acc: 0.9790\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0817 - acc: 0.9755 - val_loss: 0.0359 - val_acc: 0.9870\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0523 - acc: 0.9840 - val_loss: 0.0344 - val_acc: 0.9885\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0410 - acc: 0.9871 - val_loss: 0.0262 - val_acc: 0.9917\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0327 - acc: 0.9901 - val_loss: 0.0329 - val_acc: 0.9905\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0247 - val_acc: 0.9920\n",
      "Epoch 7/12\n",
      "52352/60000 [=========================>....] - ETA: 1s - loss: 0.0248 - acc: 0.9922"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hauptmethode\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DURCHGÄNGE = 6 # variable to clarify number of generations\n",
    "actualpop= initialise()\n",
    "\n",
    "#actualpop= entschachteln(actualpop)\n",
    "evalaccuris = []\n",
    "saved = actualpop\n",
    "i = 1\n",
    "    \n",
    "while i < DURCHGÄNGE+1:\n",
    "    \n",
    "    nummer = i\n",
    "    accuri = netzdurchlauf(actualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(accuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(accuri))\n",
    "    #print(actualpop)\n",
    "    actualpop = fortpflanzung(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "   \n",
    "    evalaccuris.append([i ,np.amax(accuri), sum(accuri)/len(accuri)])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The highest accuracies in population')\n",
    "print(evalaccuris)  \n",
    "\n",
    "print('Wartezeit: ')\n",
    "end = time.time()\n",
    "seconds = end - start\n",
    "minutes = seconds / 60\n",
    "print(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation\n",
    "df = pd.DataFrame(data =evalaccuris)\n",
    "df.rename(columns={0: 'Generation',1:'Accuracy Best',2: 'Accuracy mean'}, inplace=True)\n",
    "df\n",
    "sns.regplot(x=df['Generation'],y=df['Accuracy Best'])\n",
    "plt.ylim(0.990, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation von dem durchschnitt der accuracy\n",
    "\n",
    "sns.regplot(x=df['Generation'],y=df['Accuracy mean'])\n",
    "plt.ylim(0.990, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
