{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random start of population\n",
    "#genomes as a list of gene sequences\n",
    "def initialise():\n",
    "    genomes =[]\n",
    "    for i in range(2):\n",
    "        genomes.append([np.random.randint(2, size=6)]) # add 5 randomly initialised indiviudals\n",
    "    \n",
    "    return genomes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "\n",
    "def paring(mom,dad):\n",
    "    return(np.concatenate((mom[:3], dad[3:]), axis=0))\n",
    "\n",
    "\n",
    "def mutation(popul):\n",
    "    position = random.randrange(0, len(popul))\n",
    "    gencode = popul[position]\n",
    "    \n",
    "    decider = random.uniform(0, 1)\n",
    "    posi = 0\n",
    "    if decider < 0.2 :\n",
    "        print('Mutation')\n",
    "        posi = random.randrange(0, len(gencode))\n",
    "    \n",
    "        if gencode[posi] == 1:\n",
    "            gencode[posi] = 0\n",
    "        elif gencode[posi] == 0:\n",
    "            gencode[posi] = 1\n",
    "            \n",
    "    popul[position] = np.array(gencode)\n",
    "    \n",
    "    return popul\n",
    "\n",
    "\n",
    "def selected(maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-2:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "  \n",
    "    for ind in indices:\n",
    "    \n",
    "        for k in actualpop[ind]:\n",
    "         \n",
    "         \n",
    "            k=list(k)\n",
    "            parents.append(k)\n",
    "   \n",
    "    \n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs\n",
    "\n",
    "\n",
    "def selected2(maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-2:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "   \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "            \n",
    "   \n",
    "    \n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netzdurchlauf(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "        batch_size = 128\n",
    "        num_classes = 10\n",
    "        epochs = 12\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "        for gen in element:\n",
    "            if (gen== 0):\n",
    "                model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            elif (gen == 1):\n",
    "                model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# umschreiben ist nur der erste durchlauf\n",
    "\n",
    "def netzdurchlauf1(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "        for indiv in element:\n",
    "            batch_size = 128\n",
    "            num_classes = 10\n",
    "            epochs = 12\n",
    "\n",
    "            # input image dimensions\n",
    "            img_rows, img_cols = 28, 28\n",
    "\n",
    "            # the data, split between train and test sets\n",
    "            (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "                x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "                input_shape = (1, img_rows, img_cols)\n",
    "            else:\n",
    "                x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "                x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "                input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "            x_train = x_train.astype('float32')\n",
    "            x_test = x_test.astype('float32')\n",
    "            x_train /= 255\n",
    "            x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "            # convert class vectors to binary class matrices\n",
    "            y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "            y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                             activation='relu',\n",
    "                             input_shape=input_shape))\n",
    "            model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "            for gen in indiv:\n",
    "                if (gen== 0):\n",
    "                    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "                elif (gen == 1):\n",
    "                    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            model.add(Flatten())\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "            score = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "            accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelle Population\n",
      "[[array([1, 1, 1, 1, 0, 1])], [array([1, 1, 1, 0, 1, 0])]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0914 15:36:30.713404  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0914 15:36:30.729377  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0914 15:36:30.731361  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0914 15:36:30.763274  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0914 15:36:30.765281  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0914 15:36:30.774215  1892 deprecation.py:506] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0914 15:36:30.951769  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0914 15:36:30.959749  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0914 15:36:31.116347  1892 deprecation.py:323] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.2609 - acc: 0.9184 - val_loss: 0.0667 - val_acc: 0.9803\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0815 - acc: 0.9760 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0618 - acc: 0.9811 - val_loss: 0.0431 - val_acc: 0.9855\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0518 - acc: 0.9845 - val_loss: 0.0374 - val_acc: 0.9885\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0329 - val_acc: 0.9893\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0402 - acc: 0.9880 - val_loss: 0.0343 - val_acc: 0.9883\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0352 - acc: 0.9889 - val_loss: 0.0294 - val_acc: 0.9899\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0299 - val_acc: 0.9894\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0299 - acc: 0.9908 - val_loss: 0.0293 - val_acc: 0.9903\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0271 - acc: 0.9916 - val_loss: 0.0286 - val_acc: 0.9896\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0281 - val_acc: 0.9905\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0331 - val_acc: 0.9896\n",
      "Test loss: 0.03309797278128681\n",
      "Test accuracy: 0.9896\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.2708 - acc: 0.9147 - val_loss: 0.0690 - val_acc: 0.9765\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0752 - acc: 0.9773 - val_loss: 0.0427 - val_acc: 0.9852\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0557 - acc: 0.9831 - val_loss: 0.0402 - val_acc: 0.9860\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0300 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0388 - acc: 0.9879 - val_loss: 0.0282 - val_acc: 0.9904\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0344 - acc: 0.9893 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0283 - acc: 0.9908 - val_loss: 0.0232 - val_acc: 0.9926\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0268 - acc: 0.9913 - val_loss: 0.0283 - val_acc: 0.9908\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0235 - acc: 0.9923 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0222 - acc: 0.9931 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.0205 - val_acc: 0.9928\n",
      "Test loss: 0.020535377434952533\n",
      "Test accuracy: 0.9928\n",
      " Accuracy of first population\n",
      "[0.9896, 0.9928]\n",
      "highest accuracy of first population:\n",
      "0.9928\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[array([1, 1, 1, 0, 1, 0])]\n",
      "jj\n",
      "[1 1 1 0 1 0]\n",
      "jj\n",
      "[array([1, 1, 1, 1, 0, 1])]\n",
      "jj\n",
      "[1 1 1 1 0 1]\n",
      "The highest accuracies in population\n",
      "[[1, 0.9928]]\n",
      "[[array([1, 1, 1, 1, 0, 1])], [array([1, 1, 1, 0, 1, 0])]]\n",
      "[array([1, 1, 1, 1, 0, 1]), array([1, 1, 1, 0, 1, 0])]\n",
      "Aktuelle Population\n",
      "[array([1, 1, 1, 1, 0, 1]), array([1, 1, 1, 0, 1, 0])]\n",
      "Element\n",
      "[1 1 1 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.2562 - acc: 0.9221 - val_loss: 0.0717 - val_acc: 0.9776\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0791 - acc: 0.9756 - val_loss: 0.0447 - val_acc: 0.9860\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0592 - acc: 0.9818 - val_loss: 0.0434 - val_acc: 0.9854\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0504 - acc: 0.9839 - val_loss: 0.0434 - val_acc: 0.9851\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0424 - acc: 0.9871 - val_loss: 0.0424 - val_acc: 0.9854\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0389 - acc: 0.9877 - val_loss: 0.0327 - val_acc: 0.9889\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0357 - acc: 0.9891 - val_loss: 0.0329 - val_acc: 0.9894\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0312 - acc: 0.9905 - val_loss: 0.0287 - val_acc: 0.9899\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0358 - val_acc: 0.9879\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0268 - val_acc: 0.9911\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0285 - val_acc: 0.9902\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0309 - val_acc: 0.9904\n",
      "Test loss: 0.030852017250056814\n",
      "Test accuracy: 0.9904\n",
      "Element\n",
      "[1 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.2574 - acc: 0.9185 - val_loss: 0.0553 - val_acc: 0.9821\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0777 - acc: 0.9767 - val_loss: 0.0491 - val_acc: 0.9855\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0557 - acc: 0.9829 - val_loss: 0.0304 - val_acc: 0.9891\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0464 - acc: 0.9860 - val_loss: 0.0330 - val_acc: 0.9901\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0399 - acc: 0.9882 - val_loss: 0.0278 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0354 - acc: 0.9890 - val_loss: 0.0265 - val_acc: 0.9913\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0234 - val_acc: 0.9922\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0286 - acc: 0.9913 - val_loss: 0.0252 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0219 - val_acc: 0.9923\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.0258 - val_acc: 0.9929\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0200 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0213 - acc: 0.9931 - val_loss: 0.0241 - val_acc: 0.9917\n",
      "Test loss: 0.024055037741863634\n",
      "Test accuracy: 0.9917\n",
      " Accuracy of populationnummer: \n",
      "1\n",
      "[0.9904, 0.9917]\n",
      "highest accuracy of populationnummer: \n",
      "1\n",
      "0.9917\n",
      "###########################################\n",
      "[array([1, 1, 1, 1, 0, 1]), array([1, 1, 1, 0, 1, 0])]\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[1 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 1 1 0 1]\n",
      "jj\n",
      "Mutation\n",
      "Aktuelle Population\n",
      "[array([1, 1, 1, 0, 1, 0]), array([1, 1, 0, 1, 0, 1])]\n",
      "Element\n",
      "[1 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.2571 - acc: 0.9203 - val_loss: 0.0588 - val_acc: 0.9819\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0774 - acc: 0.9765 - val_loss: 0.0400 - val_acc: 0.9881\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0562 - acc: 0.9826 - val_loss: 0.0352 - val_acc: 0.9892\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0460 - acc: 0.9859 - val_loss: 0.0339 - val_acc: 0.9896\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0403 - acc: 0.9878 - val_loss: 0.0320 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0349 - acc: 0.9890 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0321 - acc: 0.9897 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0301 - acc: 0.9908 - val_loss: 0.0232 - val_acc: 0.9923\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 0.0245 - val_acc: 0.9921\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.0232 - val_acc: 0.9933\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0237 - val_acc: 0.9923\n",
      "Test loss: 0.023672192190159695\n",
      "Test accuracy: 0.9923\n",
      "Element\n",
      "[1 1 0 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.2584 - acc: 0.9192 - val_loss: 0.0529 - val_acc: 0.9832\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0701 - acc: 0.9778 - val_loss: 0.0619 - val_acc: 0.9804\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0494 - acc: 0.9851 - val_loss: 0.0288 - val_acc: 0.9906\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0405 - acc: 0.9874 - val_loss: 0.0325 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0346 - acc: 0.9892 - val_loss: 0.0246 - val_acc: 0.9919\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0240 - val_acc: 0.9922\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.0264 - val_acc: 0.9912\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0249 - val_acc: 0.9909\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.0312 - val_acc: 0.9914\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0200 - val_acc: 0.9928\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0251 - val_acc: 0.9915\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0163 - acc: 0.9947 - val_loss: 0.0255 - val_acc: 0.9914\n",
      "Test loss: 0.025537678397136915\n",
      "Test accuracy: 0.9914\n",
      " Accuracy of populationnummer: \n",
      "2\n",
      "[0.9923, 0.9914]\n",
      "highest accuracy of populationnummer: \n",
      "2\n",
      "0.9923\n",
      "###########################################\n",
      "[array([1, 1, 1, 0, 1, 0]), array([1, 1, 0, 1, 0, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "TEST\n",
      "jj\n",
      "[1 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 0 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([1, 1, 0, 0, 1, 0]), array([1, 1, 1, 1, 0, 1])]\n",
      "Element\n",
      "[1 1 0 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.2816 - acc: 0.9096 - val_loss: 0.0687 - val_acc: 0.9776\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0770 - acc: 0.9763 - val_loss: 0.0436 - val_acc: 0.9855\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0528 - acc: 0.9841 - val_loss: 0.0303 - val_acc: 0.9904\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0425 - acc: 0.9864 - val_loss: 0.0248 - val_acc: 0.9911\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0366 - acc: 0.9884 - val_loss: 0.0234 - val_acc: 0.9913\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0315 - acc: 0.9898 - val_loss: 0.0225 - val_acc: 0.9923\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.0221 - val_acc: 0.9922\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0254 - acc: 0.9923 - val_loss: 0.0249 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0204 - val_acc: 0.9935\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0178 - acc: 0.9941 - val_loss: 0.0275 - val_acc: 0.9910\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0220 - val_acc: 0.9930\n",
      "Test loss: 0.021976915729825488\n",
      "Test accuracy: 0.993\n",
      "Element\n",
      "[1 1 1 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.2410 - acc: 0.9250 - val_loss: 0.0869 - val_acc: 0.9740\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.0809 - acc: 0.9763 - val_loss: 0.0618 - val_acc: 0.9802\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0618 - acc: 0.9813 - val_loss: 0.0478 - val_acc: 0.9848\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0518 - acc: 0.9844 - val_loss: 0.0340 - val_acc: 0.9872\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0439 - acc: 0.9862 - val_loss: 0.0337 - val_acc: 0.9881\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0383 - acc: 0.9882 - val_loss: 0.0348 - val_acc: 0.9871\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0316 - val_acc: 0.9898\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0288 - val_acc: 0.9903\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.0277 - acc: 0.9915 - val_loss: 0.0303 - val_acc: 0.9893\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0281 - val_acc: 0.9906\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.0265 - val_acc: 0.9915\n",
      "Test loss: 0.026529711793546448\n",
      "Test accuracy: 0.9915\n",
      " Accuracy of populationnummer: \n",
      "3\n",
      "[0.993, 0.9915]\n",
      "highest accuracy of populationnummer: \n",
      "3\n",
      "0.993\n",
      "###########################################\n",
      "[array([1, 1, 0, 0, 1, 0]), array([1, 1, 1, 1, 0, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "TEST\n",
      "jj\n",
      "[1 1 0 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 1 1 0 1]\n",
      "jj\n",
      "Mutation\n",
      "Aktuelle Population\n",
      "[array([0, 1, 1, 0, 1, 0]), array([1, 1, 0, 1, 0, 1])]\n",
      "Element\n",
      "[0 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.3208 - acc: 0.8961 - val_loss: 0.0636 - val_acc: 0.9798\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0794 - acc: 0.9755 - val_loss: 0.0499 - val_acc: 0.9844\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0552 - acc: 0.9831 - val_loss: 0.0295 - val_acc: 0.9906\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0450 - acc: 0.9865 - val_loss: 0.0287 - val_acc: 0.9902\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0378 - acc: 0.9889 - val_loss: 0.0296 - val_acc: 0.9906\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0314 - acc: 0.9904 - val_loss: 0.0268 - val_acc: 0.9916\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0288 - acc: 0.9906 - val_loss: 0.0238 - val_acc: 0.9917\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0214 - val_acc: 0.9928\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0238 - acc: 0.9925 - val_loss: 0.0235 - val_acc: 0.9930\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0221 - val_acc: 0.9926\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "Test loss: 0.01921124537798969\n",
      "Test accuracy: 0.9943\n",
      "Element\n",
      "[1 1 0 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.2546 - acc: 0.9206 - val_loss: 0.0572 - val_acc: 0.9792\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0697 - acc: 0.9778 - val_loss: 0.0409 - val_acc: 0.9869\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0501 - acc: 0.9844 - val_loss: 0.0302 - val_acc: 0.9898\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0406 - acc: 0.9875 - val_loss: 0.0307 - val_acc: 0.9896\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0348 - acc: 0.9897 - val_loss: 0.0241 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0300 - acc: 0.9909 - val_loss: 0.0350 - val_acc: 0.9892\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0248 - val_acc: 0.9916\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0233 - acc: 0.9931 - val_loss: 0.0261 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0219 - val_acc: 0.9928\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0211 - val_acc: 0.9931\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0173 - acc: 0.9947 - val_loss: 0.0204 - val_acc: 0.9930\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0246 - val_acc: 0.9928\n",
      "Test loss: 0.024612322326923095\n",
      "Test accuracy: 0.9928\n",
      " Accuracy of populationnummer: \n",
      "4\n",
      "[0.9943, 0.9928]\n",
      "highest accuracy of populationnummer: \n",
      "4\n",
      "0.9943\n",
      "###########################################\n",
      "[array([0, 1, 1, 0, 1, 0]), array([1, 1, 0, 1, 0, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "TEST\n",
      "jj\n",
      "[0 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 0 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([1, 1, 0, 0, 1, 0]), array([0, 1, 1, 1, 0, 1])]\n",
      "Element\n",
      "[1 1 0 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.2987 - acc: 0.9047 - val_loss: 0.0590 - val_acc: 0.9821\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0791 - acc: 0.9755 - val_loss: 0.0375 - val_acc: 0.9873\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0569 - acc: 0.9826 - val_loss: 0.0287 - val_acc: 0.9902\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0426 - acc: 0.9867 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0367 - acc: 0.9883 - val_loss: 0.0253 - val_acc: 0.9912\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0322 - acc: 0.9903 - val_loss: 0.0230 - val_acc: 0.9923\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0286 - acc: 0.9908 - val_loss: 0.0205 - val_acc: 0.9933\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0254 - acc: 0.9919 - val_loss: 0.0239 - val_acc: 0.9921\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0202 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0208 - acc: 0.9933 - val_loss: 0.0210 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0212 - val_acc: 0.9930\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0274 - val_acc: 0.9930\n",
      "Test loss: 0.02743835742360925\n",
      "Test accuracy: 0.993\n",
      "Element\n",
      "[0 1 1 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.2684 - acc: 0.9155 - val_loss: 0.0701 - val_acc: 0.9796\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0738 - acc: 0.9781 - val_loss: 0.0500 - val_acc: 0.9832\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0553 - acc: 0.9833 - val_loss: 0.0414 - val_acc: 0.9874\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0439 - acc: 0.9861 - val_loss: 0.0430 - val_acc: 0.9874\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0369 - acc: 0.9887 - val_loss: 0.0359 - val_acc: 0.9889\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0328 - acc: 0.9899 - val_loss: 0.0269 - val_acc: 0.9913\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0296 - acc: 0.9902 - val_loss: 0.0317 - val_acc: 0.9893\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0264 - acc: 0.9917 - val_loss: 0.0252 - val_acc: 0.9922\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0238 - acc: 0.9927 - val_loss: 0.0293 - val_acc: 0.9908\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0215 - val_acc: 0.9927\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0206 - acc: 0.9934 - val_loss: 0.0249 - val_acc: 0.9916\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0275 - val_acc: 0.9919\n",
      "Test loss: 0.02753172825004094\n",
      "Test accuracy: 0.9919\n",
      " Accuracy of populationnummer: \n",
      "5\n",
      "[0.993, 0.9919]\n",
      "highest accuracy of populationnummer: \n",
      "5\n",
      "0.993\n",
      "###########################################\n",
      "[array([1, 1, 0, 0, 1, 0]), array([0, 1, 1, 1, 0, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "TEST\n",
      "jj\n",
      "[1 1 0 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[0 1 1 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([1, 1, 0, 1, 0, 1]), array([0, 1, 1, 0, 1, 0])]\n",
      "Element\n",
      "[1 1 0 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.2642 - acc: 0.9172 - val_loss: 0.0622 - val_acc: 0.9794\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0696 - acc: 0.9786 - val_loss: 0.0448 - val_acc: 0.9851\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0507 - acc: 0.9844 - val_loss: 0.0336 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0399 - acc: 0.9877 - val_loss: 0.0275 - val_acc: 0.9910\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0352 - acc: 0.9887 - val_loss: 0.0307 - val_acc: 0.9908\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0294 - acc: 0.9911 - val_loss: 0.0300 - val_acc: 0.9898\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 0.0307 - val_acc: 0.9891\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0238 - acc: 0.9926 - val_loss: 0.0248 - val_acc: 0.9915\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0241 - val_acc: 0.9918\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0231 - val_acc: 0.9926\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0237 - val_acc: 0.9929\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0279 - val_acc: 0.9907\n",
      "Test loss: 0.02787275015717314\n",
      "Test accuracy: 0.9907\n",
      "Element\n",
      "[0 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.3058 - acc: 0.9031 - val_loss: 0.0621 - val_acc: 0.9803\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0880 - acc: 0.9730 - val_loss: 0.0406 - val_acc: 0.9858\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0622 - acc: 0.9808 - val_loss: 0.0345 - val_acc: 0.9898\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0506 - acc: 0.9848 - val_loss: 0.0379 - val_acc: 0.9872\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0404 - acc: 0.9872 - val_loss: 0.0288 - val_acc: 0.9910\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0352 - acc: 0.9891 - val_loss: 0.0300 - val_acc: 0.9907\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0316 - acc: 0.9905 - val_loss: 0.0228 - val_acc: 0.9926\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0227 - val_acc: 0.9926\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0264 - acc: 0.9916 - val_loss: 0.0198 - val_acc: 0.9928\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0235 - acc: 0.9920 - val_loss: 0.0242 - val_acc: 0.9924\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0203 - val_acc: 0.9937\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0196 - val_acc: 0.9936\n",
      "Test loss: 0.01963336994411875\n",
      "Test accuracy: 0.9936\n",
      " Accuracy of populationnummer: \n",
      "6\n",
      "[0.9907, 0.9936]\n",
      "highest accuracy of populationnummer: \n",
      "6\n",
      "0.9936\n",
      "###########################################\n",
      "[array([1, 1, 0, 1, 0, 1]), array([0, 1, 1, 0, 1, 0])]\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[0 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 0 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([0, 1, 1, 1, 0, 1]), array([1, 1, 0, 0, 1, 0])]\n",
      "Element\n",
      "[0 1 1 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.2848 - acc: 0.9112 - val_loss: 0.0589 - val_acc: 0.9809\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0746 - acc: 0.9769 - val_loss: 0.0515 - val_acc: 0.9826\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0541 - acc: 0.9835 - val_loss: 0.0538 - val_acc: 0.9838\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0433 - acc: 0.9869 - val_loss: 0.0329 - val_acc: 0.9888\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0370 - acc: 0.9887 - val_loss: 0.0293 - val_acc: 0.9909\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.0285 - val_acc: 0.9913\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0292 - acc: 0.9907 - val_loss: 0.0261 - val_acc: 0.9915\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0269 - val_acc: 0.9909\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0219 - acc: 0.9932 - val_loss: 0.0230 - val_acc: 0.9926\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0199 - acc: 0.9933 - val_loss: 0.0239 - val_acc: 0.9931\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0238 - val_acc: 0.9929\n",
      "Test loss: 0.023819334018939844\n",
      "Test accuracy: 0.9929\n",
      "Element\n",
      "[1 1 0 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.3035 - acc: 0.9045 - val_loss: 0.0605 - val_acc: 0.9796\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0758 - acc: 0.9769 - val_loss: 0.0385 - val_acc: 0.9874\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0543 - acc: 0.9833 - val_loss: 0.0341 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0433 - acc: 0.9864 - val_loss: 0.0294 - val_acc: 0.9903\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0359 - acc: 0.9889 - val_loss: 0.0254 - val_acc: 0.9924\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0204 - val_acc: 0.9934\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0273 - acc: 0.9916 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0180 - val_acc: 0.9944\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.0213 - val_acc: 0.9933\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0189 - val_acc: 0.9939\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0226 - val_acc: 0.9928\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0216 - val_acc: 0.9932\n",
      "Test loss: 0.021570165775906206\n",
      "Test accuracy: 0.9932\n",
      " Accuracy of populationnummer: \n",
      "7\n",
      "[0.9929, 0.9932]\n",
      "highest accuracy of populationnummer: \n",
      "7\n",
      "0.9932\n",
      "###########################################\n",
      "[array([0, 1, 1, 1, 0, 1]), array([1, 1, 0, 0, 1, 0])]\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[1 1 0 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[0 1 1 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([1, 1, 0, 1, 0, 1]), array([0, 1, 1, 0, 1, 0])]\n",
      "Element\n",
      "[1 1 0 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.2757 - acc: 0.9121 - val_loss: 0.0645 - val_acc: 0.9795\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0700 - acc: 0.9783 - val_loss: 0.0393 - val_acc: 0.9866\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0503 - acc: 0.9846 - val_loss: 0.0288 - val_acc: 0.9907\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.0303 - val_acc: 0.9887\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0334 - acc: 0.9899 - val_loss: 0.0284 - val_acc: 0.9899\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0296 - acc: 0.9908 - val_loss: 0.0237 - val_acc: 0.9919\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0266 - val_acc: 0.9907\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0231 - val_acc: 0.9927\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0242 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0218 - val_acc: 0.9932\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0229 - val_acc: 0.9924\n",
      "Test loss: 0.022948477862845176\n",
      "Test accuracy: 0.9924\n",
      "Element\n",
      "[0 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.3073 - acc: 0.9012 - val_loss: 0.0660 - val_acc: 0.9777\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0828 - acc: 0.9746 - val_loss: 0.0402 - val_acc: 0.9873\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0590 - acc: 0.9816 - val_loss: 0.0411 - val_acc: 0.9853\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0486 - acc: 0.9845 - val_loss: 0.0256 - val_acc: 0.9913\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0396 - acc: 0.9883 - val_loss: 0.0274 - val_acc: 0.9916\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0356 - acc: 0.9887 - val_loss: 0.0232 - val_acc: 0.9924\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0311 - acc: 0.9901 - val_loss: 0.0214 - val_acc: 0.9934\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0281 - acc: 0.9911 - val_loss: 0.0223 - val_acc: 0.9932\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0238 - acc: 0.9923 - val_loss: 0.0247 - val_acc: 0.9922\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0191 - val_acc: 0.9938\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0214 - acc: 0.9930 - val_loss: 0.0200 - val_acc: 0.9934\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0197 - acc: 0.9937 - val_loss: 0.0249 - val_acc: 0.9926\n",
      "Test loss: 0.024922877446013444\n",
      "Test accuracy: 0.9926\n",
      " Accuracy of populationnummer: \n",
      "8\n",
      "[0.9924, 0.9926]\n",
      "highest accuracy of populationnummer: \n",
      "8\n",
      "0.9926\n",
      "###########################################\n",
      "[array([1, 1, 0, 1, 0, 1]), array([0, 1, 1, 0, 1, 0])]\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[0 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 0 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([0, 1, 1, 1, 0, 1]), array([1, 1, 0, 0, 1, 0])]\n",
      "Element\n",
      "[0 1 1 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.2619 - acc: 0.9186 - val_loss: 0.0658 - val_acc: 0.9804\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0697 - acc: 0.9787 - val_loss: 0.0492 - val_acc: 0.9838\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0519 - acc: 0.9839 - val_loss: 0.0351 - val_acc: 0.9887\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0417 - acc: 0.9868 - val_loss: 0.0292 - val_acc: 0.9892\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0271 - val_acc: 0.9915\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0300 - acc: 0.9907 - val_loss: 0.0318 - val_acc: 0.9896\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0271 - acc: 0.9916 - val_loss: 0.0243 - val_acc: 0.9923\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0248 - acc: 0.9925 - val_loss: 0.0255 - val_acc: 0.9919\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.0227 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0214 - acc: 0.9933 - val_loss: 0.0250 - val_acc: 0.9924\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0292 - val_acc: 0.9903\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0171 - acc: 0.9945 - val_loss: 0.0235 - val_acc: 0.9924\n",
      "Test loss: 0.023478811458236305\n",
      "Test accuracy: 0.9924\n",
      "Element\n",
      "[1 1 0 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.2994 - acc: 0.9035 - val_loss: 0.0706 - val_acc: 0.9784\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0760 - acc: 0.9768 - val_loss: 0.0369 - val_acc: 0.9874\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0539 - acc: 0.9838 - val_loss: 0.0255 - val_acc: 0.9912\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0409 - acc: 0.9873 - val_loss: 0.0232 - val_acc: 0.9925\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0352 - acc: 0.9897 - val_loss: 0.0230 - val_acc: 0.9936\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0303 - acc: 0.9901 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0276 - acc: 0.9912 - val_loss: 0.0191 - val_acc: 0.9939\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0220 - val_acc: 0.9924\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0212 - acc: 0.9937 - val_loss: 0.0220 - val_acc: 0.9932\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0188 - val_acc: 0.9940\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0172 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0212 - val_acc: 0.9936\n",
      "Test loss: 0.021157595189198037\n",
      "Test accuracy: 0.9936\n",
      " Accuracy of populationnummer: \n",
      "9\n",
      "[0.9924, 0.9936]\n",
      "highest accuracy of populationnummer: \n",
      "9\n",
      "0.9936\n",
      "###########################################\n",
      "[array([0, 1, 1, 1, 0, 1]), array([1, 1, 0, 0, 1, 0])]\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[1 1 0 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[0 1 1 1 0 1]\n",
      "jj\n",
      "Mutation\n",
      "The highest accuracies in population\n",
      "[[1, 0.9928], [2, 0.9917], [3, 0.9923], [4, 0.993], [5, 0.9943], [6, 0.993], [7, 0.9936], [8, 0.9932], [9, 0.9926], [10, 0.9936]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hauptmethode\n",
    "\n",
    "DURCHGNGE = 10 # variable to clarify number of generations\n",
    "actualpop= initialise()\n",
    "evalaccuris = []\n",
    "saved = actualpop\n",
    "i = 0\n",
    "if i == 0:\n",
    "    accuri = netzdurchlauf1(actualpop)\n",
    "    print(' Accuracy of first population')\n",
    "    print(accuri)\n",
    "    print('highest accuracy of first population:')\n",
    "    print(np.amax(accuri))\n",
    "    actualpop = selected(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "    evalaccuris.append([i +1 ,np.amax(accuri)])\n",
    "    i= i+1\n",
    "    \n",
    "    \n",
    "while i < DURCHGNGE:\n",
    "    \n",
    "    nummer = i\n",
    "    accuri = netzdurchlauf(actualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(accuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(accuri))\n",
    "    print(actualpop)\n",
    "    actualpop = selected2(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "    \n",
    "    evalaccuris.append([i +1 ,np.amax(accuri)])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The highest accuracies in population')\n",
    "print(evalaccuris)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(data =evalaccuris)\n",
    "df.rename(columns={0: 'Generation',1:'Accuracy'}, inplace=True)\n",
    "sns.regplot(x=df['Generation'],y=df['Accuracy'])\n",
    "plt.ylim(0.990, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
