{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([1, 1, 0, 1, 0])], [array([1, 1, 0, 1, 0])]]\n"
     ]
    }
   ],
   "source": [
    "#genomes as a list of gene sequences\n",
    "genomes =[]\n",
    "for i in range(2):\n",
    "    genomes.append([np.random.randint(2, size=5)]) # add 5 randomly initialised indiviudals\n",
    "\n",
    "    \n",
    "print (genomes)\n",
    "\n",
    "accuracy_of_population= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0]\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 36s 608us/step - loss: 0.2654 - acc: 0.9167 - val_loss: 0.0556 - val_acc: 0.9830\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 0.0733 - acc: 0.9770 - val_loss: 0.0507 - val_acc: 0.9863\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 38s 626us/step - loss: 0.0530 - acc: 0.9837 - val_loss: 0.0318 - val_acc: 0.9891\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.0436 - acc: 0.9863 - val_loss: 0.0274 - val_acc: 0.9900\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 36s 606us/step - loss: 0.0384 - acc: 0.9883 - val_loss: 0.0254 - val_acc: 0.9908\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 35s 586us/step - loss: 0.0331 - acc: 0.9899 - val_loss: 0.0258 - val_acc: 0.9912\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 35s 590us/step - loss: 0.0292 - acc: 0.9909 - val_loss: 0.0226 - val_acc: 0.9924\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 35s 583us/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.0246 - val_acc: 0.9921\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 35s 585us/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.0228 - val_acc: 0.9929\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.0216 - acc: 0.9933 - val_loss: 0.0210 - val_acc: 0.9937\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 36s 606us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.0204 - val_acc: 0.9934\n",
      "Epoch 12/12\n",
      "22400/60000 [==========>...................] - ETA: 20s - loss: 0.0194 - acc: 0.9938"
     ]
    }
   ],
   "source": [
    "for element in genomes:\n",
    "    for indiv in element:\n",
    "        print(indiv)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    ########\n",
    "\n",
    "    for gen in indiv:\n",
    "        if (gen== 0):\n",
    "            model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        elif (gen == 1):\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    accuracy_of_population.append(score[0])\n",
    "\n",
    "print(accuracy_of_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
