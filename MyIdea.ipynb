{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random start of population\n",
    "#genomes as a list of gene sequences\n",
    "def initialise():\n",
    "    genomes =[]\n",
    "    for i in range(2):\n",
    "        genomes.append([np.random.randint(2, size=6)]) # add 5 randomly initialised indiviudals\n",
    "\n",
    "\n",
    "#     print (genomes)\n",
    "    \n",
    "    return genomes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "\n",
    "def paring(mom,dad):\n",
    "    return(np.concatenate((mom[:3], dad[3:]), axis=0))\n",
    "\n",
    "\n",
    "def mutation(popul):\n",
    "    position = random.randrange(0, len(popul))\n",
    "    gencode = popul[position]\n",
    "    \n",
    "    decider = random.uniform(0, 1)\n",
    "    posi = 0\n",
    "    if decider < 0.2 :\n",
    "        print('Mutation')\n",
    "        posi = random.randrange(0, len(gencode))\n",
    "    \n",
    "        if gencode[posi] == 1:\n",
    "            gencode[posi] = 0\n",
    "        elif gencode[posi] == 0:\n",
    "            gencode[posi] = 1\n",
    "            \n",
    "    popul[position] = np.array(gencode)\n",
    "    \n",
    "    return popul\n",
    "\n",
    "\n",
    "def selected(maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-2:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "    print('TEST')\n",
    "    for ind in indices:\n",
    "        r = 0\n",
    "        print('jj')\n",
    "        print(actualpop[ind])\n",
    "        print('jj')\n",
    "        for k in actualpop[ind]:\n",
    "            print(k)\n",
    "         \n",
    "            k=list(k)\n",
    "            parents.append(k)\n",
    "            r = r+1\n",
    "   \n",
    "    \n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs\n",
    "\n",
    "\n",
    "def selected2(maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-2:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "    print('TEST')\n",
    "    for ind in indices:\n",
    "       \n",
    "        print('jj')\n",
    "        print(actualpop[ind])\n",
    "        print('jj')\n",
    "        \n",
    "        parents.append(actualpop[ind])\n",
    "            \n",
    "   \n",
    "    \n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netzdurchlauf(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "        print('Element')\n",
    "        print(element)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        batch_size = 128\n",
    "        num_classes = 10\n",
    "        epochs = 12\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "        for gen in element:\n",
    "            if (gen== 0):\n",
    "                model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            elif (gen == 1):\n",
    "                model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# umschreiben ist nur der erste durchlauf\n",
    "\n",
    "def netzdurchlauf1(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "#         print('Element')\n",
    "#         print(element)\n",
    "        for indiv in element:\n",
    "#             print(indiv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            batch_size = 128\n",
    "            num_classes = 10\n",
    "            epochs = 12\n",
    "\n",
    "            # input image dimensions\n",
    "            img_rows, img_cols = 28, 28\n",
    "\n",
    "            # the data, split between train and test sets\n",
    "            (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "                x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "                input_shape = (1, img_rows, img_cols)\n",
    "            else:\n",
    "                x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "                x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "                input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "            x_train = x_train.astype('float32')\n",
    "            x_test = x_test.astype('float32')\n",
    "            x_train /= 255\n",
    "            x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "            # convert class vectors to binary class matrices\n",
    "            y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "            y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                             activation='relu',\n",
    "                             input_shape=input_shape))\n",
    "            model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "            for gen in indiv:\n",
    "                if (gen== 0):\n",
    "                    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "                elif (gen == 1):\n",
    "                    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            model.add(Flatten())\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "            score = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "            accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"NEW Population :\")\n",
    "# actualpop= selected(accuracy_of_population)\n",
    "# print(actualpop)\n",
    "# actualpop = mutation(actualpop)\n",
    "# print(actualpop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelle Population\n",
      "[[array([1, 1, 1, 1, 0, 1])], [array([1, 1, 1, 0, 1, 0])]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0914 15:36:30.713404  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0914 15:36:30.729377  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0914 15:36:30.731361  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0914 15:36:30.763274  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0914 15:36:30.765281  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0914 15:36:30.774215  1892 deprecation.py:506] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0914 15:36:30.951769  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0914 15:36:30.959749  1892 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0914 15:36:31.116347  1892 deprecation.py:323] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.2609 - acc: 0.9184 - val_loss: 0.0667 - val_acc: 0.9803\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0815 - acc: 0.9760 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0618 - acc: 0.9811 - val_loss: 0.0431 - val_acc: 0.9855\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0518 - acc: 0.9845 - val_loss: 0.0374 - val_acc: 0.9885\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0329 - val_acc: 0.9893\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0402 - acc: 0.9880 - val_loss: 0.0343 - val_acc: 0.9883\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0352 - acc: 0.9889 - val_loss: 0.0294 - val_acc: 0.9899\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0299 - val_acc: 0.9894\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0299 - acc: 0.9908 - val_loss: 0.0293 - val_acc: 0.9903\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0271 - acc: 0.9916 - val_loss: 0.0286 - val_acc: 0.9896\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0281 - val_acc: 0.9905\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0331 - val_acc: 0.9896\n",
      "Test loss: 0.03309797278128681\n",
      "Test accuracy: 0.9896\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.2708 - acc: 0.9147 - val_loss: 0.0690 - val_acc: 0.9765\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0752 - acc: 0.9773 - val_loss: 0.0427 - val_acc: 0.9852\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0557 - acc: 0.9831 - val_loss: 0.0402 - val_acc: 0.9860\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0300 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0388 - acc: 0.9879 - val_loss: 0.0282 - val_acc: 0.9904\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0344 - acc: 0.9893 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0294 - val_acc: 0.9906\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0283 - acc: 0.9908 - val_loss: 0.0232 - val_acc: 0.9926\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0268 - acc: 0.9913 - val_loss: 0.0283 - val_acc: 0.9908\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0235 - acc: 0.9923 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0222 - acc: 0.9931 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.0205 - val_acc: 0.9928\n",
      "Test loss: 0.020535377434952533\n",
      "Test accuracy: 0.9928\n",
      " Accuracy of first population\n",
      "[0.9896, 0.9928]\n",
      "highest accuracy of first population:\n",
      "0.9928\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[array([1, 1, 1, 0, 1, 0])]\n",
      "jj\n",
      "[1 1 1 0 1 0]\n",
      "jj\n",
      "[array([1, 1, 1, 1, 0, 1])]\n",
      "jj\n",
      "[1 1 1 1 0 1]\n",
      "The highest accuracies in population\n",
      "[[1, 0.9928]]\n",
      "[[array([1, 1, 1, 1, 0, 1])], [array([1, 1, 1, 0, 1, 0])]]\n",
      "[array([1, 1, 1, 1, 0, 1]), array([1, 1, 1, 0, 1, 0])]\n",
      "Aktuelle Population\n",
      "[array([1, 1, 1, 1, 0, 1]), array([1, 1, 1, 0, 1, 0])]\n",
      "Element\n",
      "[1 1 1 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.2562 - acc: 0.9221 - val_loss: 0.0717 - val_acc: 0.9776\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0791 - acc: 0.9756 - val_loss: 0.0447 - val_acc: 0.9860\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0592 - acc: 0.9818 - val_loss: 0.0434 - val_acc: 0.9854\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0504 - acc: 0.9839 - val_loss: 0.0434 - val_acc: 0.9851\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0424 - acc: 0.9871 - val_loss: 0.0424 - val_acc: 0.9854\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0389 - acc: 0.9877 - val_loss: 0.0327 - val_acc: 0.9889\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0357 - acc: 0.9891 - val_loss: 0.0329 - val_acc: 0.9894\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0312 - acc: 0.9905 - val_loss: 0.0287 - val_acc: 0.9899\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0358 - val_acc: 0.9879\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.0268 - val_acc: 0.9911\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0285 - val_acc: 0.9902\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0309 - val_acc: 0.9904\n",
      "Test loss: 0.030852017250056814\n",
      "Test accuracy: 0.9904\n",
      "Element\n",
      "[1 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.2574 - acc: 0.9185 - val_loss: 0.0553 - val_acc: 0.9821\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0777 - acc: 0.9767 - val_loss: 0.0491 - val_acc: 0.9855\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0557 - acc: 0.9829 - val_loss: 0.0304 - val_acc: 0.9891\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0464 - acc: 0.9860 - val_loss: 0.0330 - val_acc: 0.9901\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0399 - acc: 0.9882 - val_loss: 0.0278 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0354 - acc: 0.9890 - val_loss: 0.0265 - val_acc: 0.9913\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0234 - val_acc: 0.9922\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0286 - acc: 0.9913 - val_loss: 0.0252 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0219 - val_acc: 0.9923\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.0258 - val_acc: 0.9929\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0200 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0213 - acc: 0.9931 - val_loss: 0.0241 - val_acc: 0.9917\n",
      "Test loss: 0.024055037741863634\n",
      "Test accuracy: 0.9917\n",
      " Accuracy of populationnummer: \n",
      "1\n",
      "[0.9904, 0.9917]\n",
      "highest accuracy of populationnummer: \n",
      "1\n",
      "0.9917\n",
      "###########################################\n",
      "[array([1, 1, 1, 1, 0, 1]), array([1, 1, 1, 0, 1, 0])]\n",
      "Highest acc at\n",
      "[1 0]\n",
      "TEST\n",
      "jj\n",
      "[1 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 1 1 0 1]\n",
      "jj\n",
      "Mutation\n",
      "Aktuelle Population\n",
      "[array([1, 1, 1, 0, 1, 0]), array([1, 1, 0, 1, 0, 1])]\n",
      "Element\n",
      "[1 1 1 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.2571 - acc: 0.9203 - val_loss: 0.0588 - val_acc: 0.9819\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0774 - acc: 0.9765 - val_loss: 0.0400 - val_acc: 0.9881\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0562 - acc: 0.9826 - val_loss: 0.0352 - val_acc: 0.9892\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0460 - acc: 0.9859 - val_loss: 0.0339 - val_acc: 0.9896\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0403 - acc: 0.9878 - val_loss: 0.0320 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0349 - acc: 0.9890 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0321 - acc: 0.9897 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0301 - acc: 0.9908 - val_loss: 0.0232 - val_acc: 0.9923\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 0.0245 - val_acc: 0.9921\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.0232 - val_acc: 0.9933\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0237 - val_acc: 0.9923\n",
      "Test loss: 0.023672192190159695\n",
      "Test accuracy: 0.9923\n",
      "Element\n",
      "[1 1 0 1 0 1]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.2584 - acc: 0.9192 - val_loss: 0.0529 - val_acc: 0.9832\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0701 - acc: 0.9778 - val_loss: 0.0619 - val_acc: 0.9804\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0494 - acc: 0.9851 - val_loss: 0.0288 - val_acc: 0.9906\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0405 - acc: 0.9874 - val_loss: 0.0325 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0346 - acc: 0.9892 - val_loss: 0.0246 - val_acc: 0.9919\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0240 - val_acc: 0.9922\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.0264 - val_acc: 0.9912\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0249 - val_acc: 0.9909\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.0312 - val_acc: 0.9914\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0200 - val_acc: 0.9928\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0251 - val_acc: 0.9915\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0163 - acc: 0.9947 - val_loss: 0.0255 - val_acc: 0.9914\n",
      "Test loss: 0.025537678397136915\n",
      "Test accuracy: 0.9914\n",
      " Accuracy of populationnummer: \n",
      "2\n",
      "[0.9923, 0.9914]\n",
      "highest accuracy of populationnummer: \n",
      "2\n",
      "0.9923\n",
      "###########################################\n",
      "[array([1, 1, 1, 0, 1, 0]), array([1, 1, 0, 1, 0, 1])]\n",
      "Highest acc at\n",
      "[0 1]\n",
      "TEST\n",
      "jj\n",
      "[1 1 1 0 1 0]\n",
      "jj\n",
      "jj\n",
      "[1 1 0 1 0 1]\n",
      "jj\n",
      "Aktuelle Population\n",
      "[array([1, 1, 0, 0, 1, 0]), array([1, 1, 1, 1, 0, 1])]\n",
      "Element\n",
      "[1 1 0 0 1 0]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.2816 - acc: 0.9096 - val_loss: 0.0687 - val_acc: 0.9776\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0770 - acc: 0.9763 - val_loss: 0.0436 - val_acc: 0.9855\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0528 - acc: 0.9841 - val_loss: 0.0303 - val_acc: 0.9904\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0425 - acc: 0.9864 - val_loss: 0.0248 - val_acc: 0.9911\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0366 - acc: 0.9884 - val_loss: 0.0234 - val_acc: 0.9913\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0315 - acc: 0.9898 - val_loss: 0.0225 - val_acc: 0.9923\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.0221 - val_acc: 0.9922\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0254 - acc: 0.9923 - val_loss: 0.0249 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0204 - val_acc: 0.9935\n",
      "Epoch 11/12\n",
      "54400/60000 [==========================>...] - ETA: 1s - loss: 0.0181 - acc: 0.9940"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hauptmethode\n",
    "\n",
    "DURCHGÄNGE = 10 # variable to clarify number of generations\n",
    "actualpop= initialise()\n",
    "evalaccuris = []\n",
    "saved = actualpop\n",
    "i = 0\n",
    "if i == 0:\n",
    "    accuri = netzdurchlauf1(actualpop)\n",
    "    print(' Accuracy of first population')\n",
    "    print(accuri)\n",
    "    print('highest accuracy of first population:')\n",
    "    print(np.amax(accuri))\n",
    "    actualpop = selected(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "    evalaccuris.append([i +1 ,np.amax(accuri)])\n",
    "    i= i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The highest accuracies in population')\n",
    "print(evalaccuris)  \n",
    "\n",
    "print(saved)\n",
    "print(actualpop)\n",
    "while i < DURCHGÄNGE:\n",
    "    \n",
    "    nummer = i\n",
    "    accuri = netzdurchlauf(actualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(accuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(accuri))\n",
    "    print('###########################################')\n",
    "    print(actualpop)\n",
    "    actualpop = selected2(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "    \n",
    "    evalaccuris.append([i +1 ,np.amax(accuri)])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The highest accuracies in population')\n",
    "print(evalaccuris)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
