{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random start of population\n",
    "#genomes as a list of gene sequences\n",
    "def initialise():\n",
    "    genomes =[]\n",
    "    for i in range(8):\n",
    "        genomes.append([np.random.randint(2, size=6)]) # add 5 randomly initialised indiviudals\n",
    "    \n",
    "    #entschachtelungsprozess\n",
    "    ent = [5]*len(genomes)\n",
    "    i = 0\n",
    "    for k in genomes:\n",
    "        for l in k:\n",
    "            \n",
    "            ent[i] =l\n",
    "            i = i+1\n",
    "    \n",
    "\n",
    "    return ent\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "\n",
    "def paring(mom,dad):\n",
    "    return(np.concatenate((mom[:3], dad[3:]), axis=0))\n",
    "\n",
    "def entschachteln(genos):\n",
    "    print(len(genos))\n",
    "    neue = [0,0]\n",
    "    i = 0\n",
    "    for k in genos:\n",
    "        for l in k:\n",
    "            print(l)\n",
    "            neue[i] =l\n",
    "            i = i+1\n",
    "\n",
    "    return (neue)\n",
    "\n",
    "def mutation(popul):\n",
    "    position = random.randrange(0, len(popul))\n",
    "    gencode = popul[position]\n",
    "    \n",
    "    decider = random.uniform(0, 1)\n",
    "    posi = 0\n",
    "    if decider < 0.1 :\n",
    "        print('Mutation')\n",
    "        posi = random.randrange(0, len(gencode))\n",
    "    \n",
    "        if gencode[posi] == 1:\n",
    "            gencode[posi] = 0\n",
    "        elif gencode[posi] == 0:\n",
    "            gencode[posi] = 1\n",
    "            \n",
    "    popul[position] = np.array(gencode)\n",
    "    \n",
    "    return popul\n",
    "\n",
    "''' A one to one replacement reproduction '''\n",
    "def selected(maxis, actualpop): \n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-4:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "   \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "            \n",
    "    print('PPPPPP')\n",
    "    print(parents)\n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    print(parents)\n",
    "    \n",
    "    #### was passiert ungerade zahl geht nicht und 50 eltern überleben\n",
    "    # 1 un2 2un3\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netzdurchlauf(acutalpop):\n",
    "    accuracy_of_population= []\n",
    "    \n",
    "    print('Aktuelle Population')\n",
    "    print(actualpop)\n",
    "    for element in actualpop:\n",
    "        batch_size = 128\n",
    "        num_classes = 10\n",
    "        epochs = 12\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "#             print('x_train shape:', x_train.shape)\n",
    "#             print(x_train.shape[0], 'train samples')\n",
    "#             print(x_test.shape[0], 'test samples')\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "        for gen in element:\n",
    "            if (gen== 0):\n",
    "                model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            elif (gen == 1):\n",
    "                model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adadelta(),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        accuracy_of_population.append(score[1])\n",
    "        \n",
    "    return (accuracy_of_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fortpflanzung (maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-3:][::-1]\n",
    "    print('Highest acc at')\n",
    "    print(indices)\n",
    "    parents= []\n",
    "    \n",
    "    \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "   \n",
    "    \n",
    "    print('PPPPPP')\n",
    "    print(parents)\n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "    print(parents)\n",
    "    #parents = entschachteln(parents)\n",
    "#     while f < len(parents)-1: \n",
    "#         mom = parents[f]\n",
    "#         f= f +1\n",
    "#         dad = parents[f]    \n",
    "        \n",
    "# #         decider = random.uniform(0, 1) # decides random how the cross-over works\n",
    "# #         if decider < 0.5 :\n",
    "# #             child = paring(mom,dad)\n",
    "# #             childs.append(child)\n",
    "# #         else:\n",
    "# #             child = paring(dad,mom)\n",
    "# #             childs.append(child)\n",
    "\n",
    "    \n",
    "#         child = paring(mom,dad)\n",
    "#         childs.append(child)\n",
    "    \n",
    "#             child = paring(dad,mom)\n",
    "#             childs.append(child)\n",
    "\n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "    print('CCCCCCC')\n",
    "    print(childs)\n",
    "    parents = np.concatenate((parents, childs), axis=0) \n",
    "    \n",
    "    print('OVERALL')\n",
    "    print(parents)\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0, 0, 1, 0, 0, 0])], [array([0, 0, 0, 1, 0, 1])], [array([1, 1, 1, 1, 0, 1])], [array([1, 0, 1, 1, 0, 1])], [array([0, 1, 1, 0, 0, 1])], [array([1, 1, 1, 1, 0, 1])], [array([1, 0, 0, 1, 1, 1])], [array([1, 0, 0, 0, 1, 0])]]\n",
      "[array([0, 0, 1, 0, 0, 0]), array([0, 0, 0, 1, 0, 1]), array([1, 1, 1, 1, 0, 1]), array([1, 0, 1, 1, 0, 1]), array([0, 1, 1, 0, 0, 1]), array([1, 1, 1, 1, 0, 1]), array([1, 0, 0, 1, 1, 1]), array([1, 0, 0, 0, 1, 0])]\n",
      "Aktuelle Population\n",
      "[array([0, 0, 1, 0, 0, 0]), array([0, 0, 0, 1, 0, 1]), array([1, 1, 1, 1, 0, 1]), array([1, 0, 1, 1, 0, 1]), array([0, 1, 1, 0, 0, 1]), array([1, 1, 1, 1, 0, 1]), array([1, 0, 0, 1, 1, 1]), array([1, 0, 0, 0, 1, 0])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0920 12:16:49.835772  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0920 12:16:49.853836  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0920 12:16:49.857972  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0920 12:16:49.915095  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0920 12:16:49.919315  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0920 12:16:49.932454  1740 deprecation.py:506] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0920 12:16:50.237292  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0920 12:16:50.252455  1740 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0920 12:16:50.541886  1740 deprecation.py:323] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 39s 648us/step - loss: 0.4640 - acc: 0.8491 - val_loss: 0.0749 - val_acc: 0.9770\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 33s 544us/step - loss: 0.0809 - acc: 0.9769 - val_loss: 0.0580 - val_acc: 0.9814\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0530 - acc: 0.9842 - val_loss: 0.0978 - val_acc: 0.9724\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.0430 - acc: 0.9878 - val_loss: 0.0231 - val_acc: 0.9929\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 33s 557us/step - loss: 0.0337 - acc: 0.9903 - val_loss: 0.0443 - val_acc: 0.9874\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.0292 - acc: 0.9917 - val_loss: 0.0207 - val_acc: 0.9940\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 33s 558us/step - loss: 0.0253 - acc: 0.9928 - val_loss: 0.0175 - val_acc: 0.9944\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 31s 523us/step - loss: 0.0201 - acc: 0.9941 - val_loss: 0.0214 - val_acc: 0.9938\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0183 - acc: 0.9944 - val_loss: 0.0208 - val_acc: 0.9945\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 33s 558us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0222 - val_acc: 0.9940\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0239 - val_acc: 0.9944\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 31s 521us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0245 - val_acc: 0.9926\n",
      "Test loss: 0.024486753800908628\n",
      "Test accuracy: 0.9926\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 33s 543us/step - loss: 0.3755 - acc: 0.8781 - val_loss: 0.0641 - val_acc: 0.9806\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0765 - acc: 0.9768 - val_loss: 0.0385 - val_acc: 0.9876\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 31s 513us/step - loss: 0.0496 - acc: 0.9852 - val_loss: 0.0328 - val_acc: 0.9892\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0400 - acc: 0.9880 - val_loss: 0.0335 - val_acc: 0.9897\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0318 - acc: 0.9902 - val_loss: 0.0279 - val_acc: 0.9911\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0260 - acc: 0.9914 - val_loss: 0.0274 - val_acc: 0.9914\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0239 - acc: 0.9929 - val_loss: 0.0206 - val_acc: 0.9930\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0222 - val_acc: 0.9918\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0203 - val_acc: 0.9936\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0163 - acc: 0.9952 - val_loss: 0.0240 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0204 - val_acc: 0.9940\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0131 - acc: 0.9959 - val_loss: 0.0194 - val_acc: 0.9947\n",
      "Test loss: 0.01943012673136168\n",
      "Test accuracy: 0.9947\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.2572 - acc: 0.9210 - val_loss: 0.0634 - val_acc: 0.9784\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0828 - acc: 0.9744 - val_loss: 0.0597 - val_acc: 0.9840\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0619 - acc: 0.9812 - val_loss: 0.0411 - val_acc: 0.9865\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0508 - acc: 0.9842 - val_loss: 0.0372 - val_acc: 0.9870\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0432 - acc: 0.9873 - val_loss: 0.0453 - val_acc: 0.9859\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0392 - acc: 0.9880 - val_loss: 0.0310 - val_acc: 0.9890\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0345 - acc: 0.9892 - val_loss: 0.0318 - val_acc: 0.9880\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.0321 - val_acc: 0.9893\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0292 - acc: 0.9911 - val_loss: 0.0325 - val_acc: 0.9899\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0259 - acc: 0.9921 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0245 - acc: 0.9925 - val_loss: 0.0297 - val_acc: 0.9911\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0224 - acc: 0.9931 - val_loss: 0.0289 - val_acc: 0.9909\n",
      "Test loss: 0.028868516256514702\n",
      "Test accuracy: 0.9909\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.2929 - acc: 0.9079 - val_loss: 0.0743 - val_acc: 0.9769\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0714 - acc: 0.9780 - val_loss: 0.0407 - val_acc: 0.9857\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0502 - acc: 0.9849 - val_loss: 0.0357 - val_acc: 0.9877\n",
      "Epoch 4/12\n",
      "35456/60000 [================>.............] - ETA: 4s - loss: 0.0428 - acc: 0.9868"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hauptmethode\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DURCHGÄNGE = 1 # variable to clarify number of generations\n",
    "actualpop= initialise()\n",
    "\n",
    "#actualpop= entschachteln(actualpop)\n",
    "evalaccuris = []\n",
    "saved = actualpop\n",
    "i = 1\n",
    "    \n",
    "while i < DURCHGÄNGE+1:\n",
    "    \n",
    "    nummer = i\n",
    "    accuri = netzdurchlauf(actualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(accuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(accuri))\n",
    "    #print(actualpop)\n",
    "    actualpop = fortpflanzung(accuri, actualpop)\n",
    "    actualpop = mutation(actualpop)\n",
    "    \n",
    "    evalaccuris.append([i ,np.amax(accuri)])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The highest accuracies in population')\n",
    "print(evalaccuris)  \n",
    "\n",
    "print('Wartezeit: ')\n",
    "end = time.time()\n",
    "seconds = end - start\n",
    "minutes = seconds / 60\n",
    "print(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation\n",
    "df = pd.DataFrame(data =evalaccuris)\n",
    "df.rename(columns={0: 'Generation',1:'Accuracy'}, inplace=True)\n",
    "df\n",
    "sns.regplot(x=df['Generation'],y=df['Accuracy'])\n",
    "plt.ylim(0.990, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
