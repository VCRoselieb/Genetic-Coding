{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_dict = { '0' : \n",
    "                    {'layer':'keras.layers.Dense',\n",
    "                 'units' : {\n",
    "                    '0' : 2,\n",
    "                    '1' : 4,\n",
    "                    '2' : 8,\n",
    "                    '3' : 16,\n",
    "                    '4' : 32,\n",
    "                    '5' : 64,\n",
    "                    '6' : 128\n",
    "                    },\n",
    "                'activation' : {\n",
    "                    '0':'linear',\n",
    "                    '1':'tanh',\n",
    "                    '2':'elu',\n",
    "                    '3':'relu',\n",
    "                    '4':'sigmoid'\n",
    "                    }\n",
    "                },\n",
    "            '1':\n",
    "                {'layer':'keras.layers.Conv2D',\n",
    "                 'filters' : {\n",
    "                    '0' : 2,\n",
    "                    '1' : 4,\n",
    "                    '2' : 8,\n",
    "                    '3' : 16,\n",
    "                    '4' : 32,\n",
    "                    '5' : 64,\n",
    "                    '6' : 128\n",
    "                    },\n",
    "                'activation':{\n",
    "                    '0':'linear',\n",
    "                    '1':'tanh',\n",
    "                    '2':'elu',\n",
    "                    '3':'relu',\n",
    "                    '4':'sigmoid'\n",
    "                    },\n",
    "                'kernel_size' : {\n",
    "                    '0': 1,\n",
    "                    '1': 3\n",
    "                    },\n",
    "                'strides' : {\n",
    "                    '0': 1,\n",
    "                    '1': 2\n",
    "                    },\n",
    "                'padding': {\n",
    "                    '0':'same'\n",
    "                    }\n",
    "                 },\n",
    "            '2':\n",
    "                {'layer':'keras.layers.CuDNNGRU',\n",
    "                 'units' : {\n",
    "                    '0' : 2,\n",
    "                    '1' : 4,\n",
    "                    '2' : 8,\n",
    "                    '3' : 16,\n",
    "                    '4' : 32,\n",
    "                    '5' : 64,\n",
    "                    '6' : 128\n",
    "                    },\n",
    "                'kernel_initializer' : {\n",
    "                    '0': 'glorot_uniform',\n",
    "                    '1': 'uniform'\n",
    "                    }\n",
    "                },\n",
    "            '3':\n",
    "                {'layer':'keras.layers.LSTM',\n",
    "                 'units': {\n",
    "                    '0' : 2,\n",
    "                    '1' : 4,\n",
    "                    '2' : 8,\n",
    "                    '3' : 16,\n",
    "                    '4' : 32,\n",
    "                    '5' : 64,\n",
    "                    '6' : 128\n",
    "                    },\n",
    "                'activation':{\n",
    "                    '0':'linear',\n",
    "                    '1':'tanh',\n",
    "                    '2':'elu',\n",
    "                    '3':'relu',\n",
    "                    '4':'sigmoid'\n",
    "                    },\n",
    "                'recurrent_activation':{\n",
    "                    '0':'hard_sigmoid',\n",
    "                    '1':'tanh',\n",
    "                    '2':'elu',\n",
    "                    '3':'relu',\n",
    "                    '4':'sigmoid',\n",
    "                    '5':'linear'\n",
    "                    },\n",
    "                'kernel_initializer' : {\n",
    "                    '0': 'glorot_uniform',\n",
    "                    '1': 'uniform'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "def construct_model(sequence,genome):\n",
    "        \"\"\"\n",
    "        Description for Dana and Viviane starts here:\n",
    "            \n",
    "            \n",
    "        This is a network cosntructor method I copied from my own project revolving around neuroevolution\n",
    "        Above, we have a dictionary that contains all the layers and their parameters that can be used by the genetic algorithm.\n",
    "        I use two variables here:\n",
    "            \n",
    "            sequence is a genome that encodes the sequence of layers. i.e [0,0,0,1,1] for a network with three Dense and 2 Conv2D layers\n",
    "            \n",
    "            genome here is a matrix containing all parameters for each layer type that is present in the sequence. For our example above\n",
    "            this variable would contain 3 lists for the Dense layers and 2 lists for the conv2D layers. i.e. [[[0,0],[5,3],[1,1]],[3,2,1,1,0],[1,4,0,0,0]].\n",
    "            \n",
    "            If we look into the neural_dict above, we see that it contains 2 sub-dictionaries for the Dense layer and 5 for the Conv2D layer.\n",
    "            This makes it easy to add new layers by simply writing the name and the parameters of the new layer into the dictionary.\n",
    "            Infact, my original program does not even use a dictionary defined in-program but simply reads in a json file so we have everything neatly organized.\n",
    "            \n",
    "        When in doubt: always remember that the input this function was originally designed for looks like this:\n",
    "            sequence = [0,0,0,1,1]\n",
    "            genome = [[[0,0],[5,3],[1,1]],[3,2,1,1,0],[1,4,0,0,0]].\n",
    "            \n",
    "        if you get a ValueError with Input '0' is incompatible with layer conv2d_ expected ndim= m found m-1, you need to add the argument \"padding='same'\" to the conv2d layer. \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #To keep track of which gene we are reading from on every chromosome, we build a list to keep track of our indeces. i.e for a dense genome we have a list of 0s for \"units\" and \"activation\"\n",
    "        index_array = np.zeros(len(genome),dtype=int)\n",
    "        \n",
    "        #We reserve memory for our model. In the following, we will add layers to our model iteratively\n",
    "        model = keras.models.Sequential()\n",
    "        \n",
    "        \n",
    "    \n",
    "        #To add a new layer to the model, we extract the necessary data from the genome and map it to a layer definition provided by the neuron dict\n",
    "        for index in sequence:\n",
    "            reader_dict = neural_dict[str(index)]\n",
    "            #We extract a list containing all parameter names from the dictonary entry relevant for the next layer. So for example ['keras.layers.Dense','units','activation'] for a dense layer\n",
    "            gene_list = list(reader_dict.keys())\n",
    "            \n",
    "            #To compile the entire layer parameters into a keras layer type object, we need to store all values in a string and then evaluate it\n",
    "            #The first necessary parameters is the layer type name. The name is found in the first entry of the dictonary.\n",
    "            code = reader_dict[str(gene_list[0])]\n",
    "            \n",
    "            gene_list = gene_list[1:]\n",
    "            #we have added the layer name to the code we want to pass into the compiler below. So we do not need it anymore.\n",
    "            code += \"(\"\n",
    "            #We now pass parameters into the layer. Since this is different for every layer, we iterate through our gene_list and add parameter names with the corresponding value from the neural_dict\n",
    "            gene_index = 0\n",
    "            for parameter in gene_list:\n",
    "                code += str(parameter)\n",
    "                code += \"=\"\n",
    "                #So for example \"units=\"\n",
    "                genome_information = genome[index][index_array[index]]\n",
    "                next_argument = reader_dict[str(parameter)][str(genome_information[gene_index])]\n",
    "                \n",
    "                if type(next_argument) is str:\n",
    "                    #repr is another way of representing strings in python. However, here we do not use strings as something that is put into the console, as is traditionally the case\n",
    "                    #Instead, strings here are necessary to construct a compilable object. Since we want to extract the value from a variable, we need to pass the variable name as a string.\n",
    "                    #we need a variable name for some layers because they can store strings themselves.\n",
    "                    #The eval function below takes every string at face value, meaning that it will not understand what you mean when you pass for example:\n",
    "                    #\"keras.layers.conv2D(filters=32,activation='relu'...)\"\n",
    "                    #it will interpret 'relu' as a variable name and thus will not compile.\n",
    "                    #If we instead use a variable that points to a specific string, it will work. Thus the repr cast here.\n",
    "                    argument_copy = repr(next_argument)\n",
    "                    code+= argument_copy\n",
    "                else:\n",
    "                    code += str(next_argument)\n",
    "                gene_index += 1\n",
    "                \n",
    "                #if we have not reached the last entry in our list, we are not done adding parameters to our code and we need to ad a comma.\n",
    "                if parameter != gene_list[-1]:\n",
    "                    code += \",\"\n",
    "            if len(model.layers) == 0:\n",
    "                code += ',input_shape='+str(input_shape)\n",
    "                #If this is our first layer, we want to add an input shape argument here so that the first layer can take input from the model.train method.\n",
    "            code += \")\"\n",
    "            index_array[index] += 1\n",
    "            \n",
    "            #The fully constructed string is passed into the online-compiler and subsequentially gets evaluated as a keras layer object. This is then added to the model\n",
    "            compiled_layer = compile(code,'<string>','eval')\n",
    "            compiled_layer = eval(compiled_layer)\n",
    "            model.add(compiled_layer)\n",
    "    \n",
    "        #in the end, our model is returned. Note that we have not added our last layer yet, as the construct_model function is universal and therefore indifferent towards the task.\n",
    "        #If we would want to classify images for example, we would need to add an additional dropout layer and a Dense with the corresponding output dimensionality and a softmax activation function.\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
