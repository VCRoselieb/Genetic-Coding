{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#several usefull imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random start of population\n",
    "#genomes as a list of gene sequences\n",
    "def initialise():\n",
    "    genomes =[]\n",
    "    for i in range(8):\n",
    "        genomes.append([np.random.randint(2, size=6)]) # add 5 randomly initialised indiviudals\n",
    "    \n",
    "    #entschachtelungsprozess\n",
    "    ent = [5]*len(genomes)\n",
    "    i = 0\n",
    "    for k in genomes:\n",
    "        for l in k:\n",
    "            \n",
    "            ent[i] =l\n",
    "            i = i+1\n",
    "    \n",
    "\n",
    "    return ent\n",
    "\n",
    "def craschcheck(popul):\n",
    "    i=0\n",
    "    for indi in popul:\n",
    "        #print(indi)\n",
    "        if check(indi) == True:\n",
    "            print('')\n",
    "            \n",
    "        if check(indi) == False:\n",
    "            indi[2] = 1\n",
    "            print(popul[i])\n",
    "            popul[i] = indi\n",
    "            print('Problem')\n",
    "        \n",
    "            \n",
    "        i = i +1\n",
    "                \n",
    "\n",
    "            \n",
    "def check(indi):\n",
    "    for gen in indi:\n",
    "        if gen == 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "#usefull functions\n",
    "\n",
    "def paring(mom,dad):\n",
    "    return(np.concatenate((mom[:3], dad[3:]), axis=0))\n",
    "\n",
    "def entschachteln(genos):\n",
    "    #print(len(genos))\n",
    "    neue = [0,0]\n",
    "    i = 0\n",
    "    for k in genos:\n",
    "        for l in k:\n",
    "            #print(l)\n",
    "            neue[i] =l\n",
    "            i = i+1\n",
    "\n",
    "    return (neue)\n",
    "\n",
    "def mutation(popul):\n",
    "    position = random.randrange(0, len(popul))\n",
    "    gencode = popul[position]\n",
    "    \n",
    "    decider = random.uniform(0, 1)\n",
    "    posi = 0\n",
    "    if decider < 0.8 :\n",
    "       \n",
    "        print('Mutation')\n",
    "        posi = random.randrange(0, len(gencode))\n",
    "    \n",
    "        if gencode[posi] == 1:\n",
    "            gencode[posi] = 0\n",
    "        elif gencode[posi] == 0:\n",
    "            gencode[posi] = 1\n",
    "            \n",
    "    popul[position] = np.array(gencode)\n",
    "    \n",
    "    return popul\n",
    "\n",
    "def mutationeach(popul):\n",
    "  \n",
    "    i = 0    \n",
    "    for gencode in popul:\n",
    "        decider = random.uniform(0, 1)\n",
    "        if decider < 0.35: \n",
    "            print('Muation')\n",
    "            posi = 0\n",
    "            posi = random.randrange(0, len(gencode))\n",
    "           \n",
    "            if gencode[posi] == 1:\n",
    "                gencode[posi] = 0\n",
    "            elif gencode[posi] == 0:\n",
    "                gencode[posi] = 1\n",
    "            \n",
    "            popul[i] = np.array(gencode)\n",
    "        \n",
    "            \n",
    "        i = i +1\n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "    return popul\n",
    "    \n",
    "\n",
    "''' A one to one replacement reproduction '''\n",
    "def OneToOneReplacement(maxis, actualpop): \n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-5:][::-1]\n",
    "    #print('Highest acc at')\n",
    "    #print(indices)\n",
    "    parents= []\n",
    "    \n",
    "   \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "    \n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    "   \n",
    "    while f < len(parents)-1: \n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        dad = parents[f]     \n",
    "        child = paring(mom,dad)\n",
    "        childs.append(child)\n",
    "        child = paring(dad,mom)\n",
    "        childs.append(child)\n",
    "        \n",
    "        \n",
    "    return childs\n",
    "\n",
    "\n",
    "def fortpflanzung (maxis, actualpop):\n",
    "    childs= []\n",
    "    maxis= np.array(maxis)\n",
    "    indices = maxis.argsort()[-4:][::-1] # hier verändern, wenn wir individuen anzahl erhöhen die erste zahl muss die hälfte der anzahl sein\n",
    "    #print('Highest acc at')\n",
    "    #print(indices)\n",
    "    parents= []\n",
    "    \n",
    "    \n",
    "    for ind in indices:    \n",
    "        parents.append(actualpop[ind])\n",
    "   \n",
    "    \n",
    "\n",
    "    random.shuffle(parents)\n",
    "    f= 0\n",
    " \n",
    "    \n",
    "    while f < len(parents): \n",
    "        #print(f)\n",
    "        f = f -1\n",
    "        mom = parents[f]\n",
    "        f= f +1\n",
    "        #print(f)\n",
    "        dad = parents[f]    \n",
    "        f= f +1\n",
    "        decider = random.uniform(0, 1) # decides random how the cross-over works\n",
    "        if decider < 0.51 :\n",
    "            child = paring(mom,dad)\n",
    "            childs.append(child)\n",
    "        else:\n",
    "            child = paring(dad,mom)\n",
    "            childs.append(child)\n",
    "\n",
    "    \n",
    "\n",
    "    parents = np.concatenate((parents, childs), axis=0) \n",
    "    random.shuffle(parents) # muss heir vllt parenets = random.shuffle(parents) hin? nochmal testen\n",
    "    \n",
    " \n",
    "    return parents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "diction = {\n",
    "    \n",
    "            'item2': 2,\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netzdurchlaufeinzeln(element):\n",
    "    \n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "            ########\n",
    "            \n",
    "            \n",
    "\n",
    "    for gen in element:\n",
    "        if (gen== 0):\n",
    "            model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        elif (gen == 1):\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaccur(popul):\n",
    "    values= []\n",
    "    for e in popul:\n",
    "        name = str(e)\n",
    "        print(str(e))\n",
    "        if name in diction:\n",
    "            print('already stored')\n",
    "            print(diction[name])\n",
    "            values.append(diction[name])\n",
    "        else:\n",
    "            print('new one')\n",
    "            wert = netzdurchlaufeinzeln(e)\n",
    "            diction[str(e) ] = wert\n",
    "            values.append(wert)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aktuelle :  [array([0, 1, 1, 0, 1, 1]), array([0, 1, 0, 0, 1, 0]), array([0, 0, 0, 1, 0, 1]), array([0, 1, 0, 1, 1, 1]), array([1, 1, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 1]), array([1, 0, 0, 0, 0, 1]), array([0, 1, 0, 1, 1, 1])]\n",
      "[0 1 1 0 1 1]\n",
      "new one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1001 16:44:35.822004  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1001 16:44:35.838958  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1001 16:44:35.840954  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1001 16:44:35.878851  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1001 16:44:35.881844  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1001 16:44:35.892816  7324 deprecation.py:506] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1001 16:44:36.082308  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1001 16:44:36.091285  7324 deprecation_wrapper.py:119] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1001 16:44:36.280809  7324 deprecation.py:323] From C:\\Users\\vivia\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 0.2820 - acc: 0.9111 - val_loss: 0.0649 - val_acc: 0.97982970 \n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0726 - acc: 0.9779 - val_loss: 0.0560 - val_acc: 0.9828\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0543 - acc: 0.9833 - val_loss: 0.0570 - val_acc: 0.9814\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0428 - acc: 0.9871 - val_loss: 0.0319 - val_acc: 0.9892\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0358 - acc: 0.9892 - val_loss: 0.0414 - val_acc: 0.9873s - loss: 0.0359 - acc: 0.\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0322 - acc: 0.9901 - val_loss: 0.0264 - val_acc: 0.9913\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0284 - acc: 0.9914 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0208 - val_acc: 0.9933\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0231 - val_acc: 0.9924\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0210 - acc: 0.9934 - val_loss: 0.0247 - val_acc: 0.9925\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0195 - acc: 0.9934 - val_loss: 0.0227 - val_acc: 0.9924\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0224 - val_acc: 0.9933\n",
      "Test loss: 0.022447706200373615\n",
      "Test accuracy: 0.9933\n",
      "[0 1 0 0 1 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.3665 - acc: 0.8803 - val_loss: 0.0626 - val_acc: 0.9795\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0782 - acc: 0.9764 - val_loss: 0.0343 - val_acc: 0.9889\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0526 - acc: 0.9838 - val_loss: 0.0522 - val_acc: 0.9821\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0414 - acc: 0.9870 - val_loss: 0.0243 - val_acc: 0.9930\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0256 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0359 - val_acc: 0.9875\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0255 - acc: 0.9916 - val_loss: 0.0215 - val_acc: 0.9936\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0219 - acc: 0.9930 - val_loss: 0.0233 - val_acc: 0.9936\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0200 - acc: 0.9941 - val_loss: 0.0307 - val_acc: 0.9911\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0224 - val_acc: 0.9925\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0165 - acc: 0.9948 - val_loss: 0.0215 - val_acc: 0.9937\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0234 - val_acc: 0.9935\n",
      "Test loss: 0.02335714698848542\n",
      "Test accuracy: 0.9935\n",
      "[0 0 0 1 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3821 - acc: 0.8746 - val_loss: 0.0712 - val_acc: 0.9765\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0782 - acc: 0.9762 - val_loss: 0.0421 - val_acc: 0.9872\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0508 - acc: 0.9846 - val_loss: 0.0338 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0392 - acc: 0.9877 - val_loss: 0.0370 - val_acc: 0.9882\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0313 - acc: 0.9906 - val_loss: 0.0219 - val_acc: 0.9933\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0264 - acc: 0.9917 - val_loss: 0.0216 - val_acc: 0.9928\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0356 - val_acc: 0.9907\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0228 - val_acc: 0.9939\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0173 - acc: 0.9946 - val_loss: 0.0259 - val_acc: 0.9926\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 0.0278 - val_acc: 0.9925\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0141 - acc: 0.9958 - val_loss: 0.0267 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0229 - val_acc: 0.9934\n",
      "Test loss: 0.022925786826009473\n",
      "Test accuracy: 0.9934\n",
      "[0 1 0 1 1 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.2977 - acc: 0.9054 - val_loss: 0.1091 - val_acc: 0.9675\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0765 - acc: 0.9770 - val_loss: 0.0469 - val_acc: 0.9860\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0558 - acc: 0.9833 - val_loss: 0.0329 - val_acc: 0.9893\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0280 - val_acc: 0.9905\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0359 - acc: 0.9891 - val_loss: 0.0313 - val_acc: 0.9902\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0320 - acc: 0.9895 - val_loss: 0.0267 - val_acc: 0.9921\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0240 - val_acc: 0.9931\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0248 - acc: 0.9922 - val_loss: 0.0309 - val_acc: 0.9904A: 3s - los\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.0237 - val_acc: 0.9919\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0227 - val_acc: 0.9932\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0227 - val_acc: 0.9934\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Test loss: 0.021742732903197975\n",
      "Test accuracy: 0.9932\n",
      "[1 1 0 1 0 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.3099 - acc: 0.9019 - val_loss: 0.0635 - val_acc: 0.9815\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0774 - acc: 0.9761 - val_loss: 0.0396 - val_acc: 0.9869\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0550 - acc: 0.9831 - val_loss: 0.0333 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0426 - acc: 0.9862 - val_loss: 0.0281 - val_acc: 0.9907\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0253 - val_acc: 0.9924\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.0258 - val_acc: 0.9909\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0280 - acc: 0.9913 - val_loss: 0.0266 - val_acc: 0.9920\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0249 - acc: 0.9924 - val_loss: 0.0204 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.0208 - val_acc: 0.9929\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0253 - val_acc: 0.9919\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.0180 - val_acc: 0.9937\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0207 - val_acc: 0.9941\n",
      "Test loss: 0.020680726096822945\n",
      "Test accuracy: 0.9941\n",
      "[0 1 1 0 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.2847 - acc: 0.9114 - val_loss: 0.0569 - val_acc: 0.9812\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0709 - acc: 0.9786 - val_loss: 0.0552 - val_acc: 0.9834\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0498 - acc: 0.9849 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0395 - acc: 0.9874 - val_loss: 0.0268 - val_acc: 0.9908\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0332 - acc: 0.9899 - val_loss: 0.0311 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0209 - val_acc: 0.9934\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0307 - val_acc: 0.9897\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0241 - val_acc: 0.9928\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0217 - val_acc: 0.9938\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0223 - val_acc: 0.9935\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0214 - val_acc: 0.9936\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0224 - val_acc: 0.9939\n",
      "Test loss: 0.022393038504745347\n",
      "Test accuracy: 0.9939\n",
      "[1 0 0 0 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.3629 - acc: 0.8826 - val_loss: 0.0591 - val_acc: 0.9813\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0721 - acc: 0.9780 - val_loss: 0.0463 - val_acc: 0.9859\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0481 - acc: 0.9858 - val_loss: 0.0234 - val_acc: 0.9908\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0369 - acc: 0.9883 - val_loss: 0.0266 - val_acc: 0.9913\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0300 - acc: 0.9908 - val_loss: 0.0241 - val_acc: 0.9918\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0230 - acc: 0.9925 - val_loss: 0.0221 - val_acc: 0.9930\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0206 - acc: 0.9932 - val_loss: 0.0221 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0222 - val_acc: 0.9929\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0230 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0198 - val_acc: 0.9940\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0229 - val_acc: 0.9928\n",
      "Test loss: 0.022889116143474213\n",
      "Test accuracy: 0.9928\n",
      "[0 1 0 1 1 1]\n",
      "already stored\n",
      "0.9932\n",
      " Accuracy of populationnummer: \n",
      "1\n",
      "[0.9933, 0.9935, 0.9934, 0.9932, 0.9941, 0.9939, 0.9928, 0.9932]\n",
      "highest accuracy of populationnummer: \n",
      "1\n",
      "0.9941\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 1 1 0 0 1]\n",
      "already stored\n",
      "0.9939\n",
      "[0 1 1 0 0 1]\n",
      "already stored\n",
      "0.9939\n",
      "[0 0 0 0 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4504 - acc: 0.8508 - val_loss: 0.0836 - val_acc: 0.9735\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0793 - acc: 0.9767 - val_loss: 0.0394 - val_acc: 0.9882\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0508 - acc: 0.9850 - val_loss: 0.0346 - val_acc: 0.9892\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0362 - acc: 0.9890 - val_loss: 0.0269 - val_acc: 0.9904\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0305 - acc: 0.9909 - val_loss: 0.0260 - val_acc: 0.9927\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0240 - acc: 0.9928 - val_loss: 0.0182 - val_acc: 0.9947\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.0211 - val_acc: 0.9934\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0233 - val_acc: 0.9929\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0160 - acc: 0.9951 - val_loss: 0.0225 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0192 - val_acc: 0.9948\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0223 - val_acc: 0.9937\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0172 - val_acc: 0.9947\n",
      "Test loss: 0.01722911161183065\n",
      "Test accuracy: 0.9947\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[0 1 0 0 1 0]\n",
      "already stored\n",
      "0.9935\n",
      "[0 1 0 0 1 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.3013 - acc: 0.9042 - val_loss: 0.0640 - val_acc: 0.9780\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0741 - acc: 0.9770 - val_loss: 0.0484 - val_acc: 0.9846\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0530 - acc: 0.9838 - val_loss: 0.0292 - val_acc: 0.9909\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0412 - acc: 0.9873 - val_loss: 0.0238 - val_acc: 0.9919\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0345 - acc: 0.9892 - val_loss: 0.0209 - val_acc: 0.9928\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0291 - acc: 0.9907 - val_loss: 0.0298 - val_acc: 0.9900\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0246 - acc: 0.9918 - val_loss: 0.0256 - val_acc: 0.9910\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0236 - acc: 0.9926 - val_loss: 0.0204 - val_acc: 0.9934\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.0217 - val_acc: 0.9930\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0194 - val_acc: 0.9938\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0193 - val_acc: 0.9939\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0143 - acc: 0.9952 - val_loss: 0.0301 - val_acc: 0.9908\n",
      "Test loss: 0.030094631445993947\n",
      "Test accuracy: 0.9908\n",
      "[1 1 0 1 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.2657 - acc: 0.9184 - val_loss: 0.0656 - val_acc: 0.9800\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0732 - acc: 0.9776 - val_loss: 0.0542 - val_acc: 0.9823\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0529 - acc: 0.9838 - val_loss: 0.0373 - val_acc: 0.9879\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0418 - acc: 0.9868 - val_loss: 0.0284 - val_acc: 0.9899\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0359 - acc: 0.9888 - val_loss: 0.0281 - val_acc: 0.9911\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0322 - acc: 0.9904 - val_loss: 0.0249 - val_acc: 0.9914\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0285 - acc: 0.9913 - val_loss: 0.0248 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0273 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0223 - acc: 0.9927 - val_loss: 0.0265 - val_acc: 0.9918\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0254 - val_acc: 0.9914\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0212 - val_acc: 0.9931\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0226 - val_acc: 0.9933\n",
      "Test loss: 0.022554006559150002\n",
      "Test accuracy: 0.9933\n",
      "[1 0 0 1 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.3113 - acc: 0.9019 - val_loss: 0.0583 - val_acc: 0.9813\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0771 - acc: 0.9762 - val_loss: 0.0388 - val_acc: 0.9874\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0547 - acc: 0.9831 - val_loss: 0.0336 - val_acc: 0.9891\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0427 - acc: 0.9877 - val_loss: 0.0437 - val_acc: 0.9849\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0360 - acc: 0.9888 - val_loss: 0.0283 - val_acc: 0.9908\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0306 - acc: 0.9909 - val_loss: 0.0244 - val_acc: 0.9917\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0263 - acc: 0.9919 - val_loss: 0.0257 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0241 - val_acc: 0.9928\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0209 - val_acc: 0.9939\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0263 - val_acc: 0.9917\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0175 - acc: 0.9945 - val_loss: 0.0188 - val_acc: 0.9937\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0236 - val_acc: 0.9925\n",
      "Test loss: 0.023611311184319857\n",
      "Test accuracy: 0.9925\n",
      " Accuracy of populationnummer: \n",
      "2\n",
      "[0.9939, 0.9939, 0.9947, 0.9934, 0.9935, 0.9908, 0.9933, 0.9925]\n",
      "highest accuracy of populationnummer: \n",
      "2\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 1 0 0 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.3603 - acc: 0.8822 - val_loss: 0.0635 - val_acc: 0.9811\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0742 - acc: 0.9773 - val_loss: 0.0446 - val_acc: 0.9850\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0511 - acc: 0.9845 - val_loss: 0.0481 - val_acc: 0.9852\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0386 - acc: 0.9879 - val_loss: 0.0280 - val_acc: 0.9908\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0230 - val_acc: 0.9927\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0263 - acc: 0.9918 - val_loss: 0.0273 - val_acc: 0.9917\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0230 - acc: 0.9931 - val_loss: 0.0221 - val_acc: 0.9931\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0292 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0192 - val_acc: 0.9938\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0158 - acc: 0.9951 - val_loss: 0.0203 - val_acc: 0.9938\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0289 - val_acc: 0.9920\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0198 - val_acc: 0.9943\n",
      "Test loss: 0.019757745059443232\n",
      "Test accuracy: 0.9943\n",
      "[0 1 1 0 0 1]\n",
      "already stored\n",
      "0.9939\n",
      "[0 1 1 1 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2593 - acc: 0.9207 - val_loss: 0.0688 - val_acc: 0.9798\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0779 - acc: 0.9755 - val_loss: 0.0440 - val_acc: 0.9850\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0568 - acc: 0.9830 - val_loss: 0.0339 - val_acc: 0.9887\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0475 - acc: 0.9852 - val_loss: 0.0379 - val_acc: 0.9871\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0395 - acc: 0.9881 - val_loss: 0.0301 - val_acc: 0.9895\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0347 - acc: 0.9893 - val_loss: 0.0382 - val_acc: 0.9880\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0306 - acc: 0.9901 - val_loss: 0.0271 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0276 - acc: 0.9913 - val_loss: 0.0290 - val_acc: 0.9904\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.0306 - val_acc: 0.9895\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0266 - val_acc: 0.9912\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0266 - val_acc: 0.9919\n",
      "Test loss: 0.026582789209659494\n",
      "Test accuracy: 0.9919\n",
      "[0 1 1 0 0 1]\n",
      "already stored\n",
      "0.9939\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[1 1 1 0 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.2556 - acc: 0.9208 - val_loss: 0.0575 - val_acc: 0.9809\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0706 - acc: 0.9787 - val_loss: 0.0398 - val_acc: 0.9872\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0506 - acc: 0.9849 - val_loss: 0.0371 - val_acc: 0.9878\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0421 - acc: 0.9866 - val_loss: 0.0314 - val_acc: 0.9898\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0345 - acc: 0.9895 - val_loss: 0.0266 - val_acc: 0.9906\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0308 - acc: 0.9908 - val_loss: 0.0282 - val_acc: 0.9907\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0266 - acc: 0.9924 - val_loss: 0.0223 - val_acc: 0.9925\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0243 - acc: 0.9926 - val_loss: 0.0215 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0217 - acc: 0.9934 - val_loss: 0.0227 - val_acc: 0.9930\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0194 - acc: 0.9939 - val_loss: 0.0214 - val_acc: 0.9928\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0217 - val_acc: 0.9928\n",
      "Test loss: 0.021656538625410757\n",
      "Test accuracy: 0.9928\n",
      "[0 1 1 0 0 1]\n",
      "already stored\n",
      "0.9939\n",
      " Accuracy of populationnummer: \n",
      "3\n",
      "[0.9943, 0.9939, 0.9919, 0.9939, 0.9947, 0.9947, 0.9928, 0.9939]\n",
      "highest accuracy of populationnummer: \n",
      "3\n",
      "0.9947\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 0 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.3647 - acc: 0.8802 - val_loss: 0.1147 - val_acc: 0.9588\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0770 - acc: 0.9761 - val_loss: 0.0344 - val_acc: 0.9887\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0502 - acc: 0.9844 - val_loss: 0.0439 - val_acc: 0.9856\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0390 - acc: 0.9883 - val_loss: 0.0359 - val_acc: 0.9888\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0320 - acc: 0.9902 - val_loss: 0.0263 - val_acc: 0.9919\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0214 - val_acc: 0.9927\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0239 - val_acc: 0.9925\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0201 - acc: 0.9939 - val_loss: 0.0190 - val_acc: 0.9944\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0175 - acc: 0.9945 - val_loss: 0.0269 - val_acc: 0.9919\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0216 - val_acc: 0.9941\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0253 - val_acc: 0.9923\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0202 - val_acc: 0.9940\n",
      "Test loss: 0.020156490756483254\n",
      "Test accuracy: 0.994\n",
      " Accuracy of populationnummer: \n",
      "4\n",
      "[0.9947, 0.9947, 0.9943, 0.9947, 0.9947, 0.9943, 0.9947, 0.994]\n",
      "highest accuracy of populationnummer: \n",
      "4\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 1 0 0 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.4477 - acc: 0.8536 - val_loss: 0.0883 - val_acc: 0.9752\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0854 - acc: 0.9756 - val_loss: 0.0493 - val_acc: 0.9840\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0574 - acc: 0.9837 - val_loss: 0.0328 - val_acc: 0.9910\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0433 - acc: 0.9877 - val_loss: 0.0326 - val_acc: 0.9908\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0352 - acc: 0.9896 - val_loss: 0.0257 - val_acc: 0.9930\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0299 - acc: 0.9914 - val_loss: 0.0203 - val_acc: 0.9948\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 0.0203 - val_acc: 0.9938\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0378 - val_acc: 0.9896\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0203 - acc: 0.9939 - val_loss: 0.0219 - val_acc: 0.9937\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0191 - val_acc: 0.9940\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 0.0273 - val_acc: 0.9922\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0140 - acc: 0.9960 - val_loss: 0.0218 - val_acc: 0.9940\n",
      "Test loss: 0.021797184547576582\n",
      "Test accuracy: 0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      " Accuracy of populationnummer: \n",
      "5\n",
      "[0.9947, 0.9947, 0.9947, 0.9947, 0.9943, 0.994, 0.9947, 0.9943]\n",
      "highest accuracy of populationnummer: \n",
      "5\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "6\n",
      "[0.9943, 0.9928, 0.9947, 0.9947, 0.9934, 0.9947, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "6\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 1 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.3801 - acc: 0.8760 - val_loss: 0.0620 - val_acc: 0.9822\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0720 - acc: 0.9782 - val_loss: 0.0296 - val_acc: 0.9909\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0489 - acc: 0.9854 - val_loss: 0.0329 - val_acc: 0.9882\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0370 - acc: 0.9884 - val_loss: 0.0493 - val_acc: 0.9848\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.0329 - val_acc: 0.9905\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0226 - acc: 0.9930 - val_loss: 0.0218 - val_acc: 0.9926\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0241 - val_acc: 0.9929\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0175 - acc: 0.9947 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0152 - acc: 0.9956 - val_loss: 0.0281 - val_acc: 0.9921\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0226 - val_acc: 0.9932\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0247 - val_acc: 0.9937\n",
      "Test loss: 0.024672429418695994\n",
      "Test accuracy: 0.9937\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 1 1]\n",
      "already stored\n",
      "0.9937\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "7\n",
      "[0.9947, 0.9937, 0.9947, 0.9947, 0.9947, 0.9937, 0.9934, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "7\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "8\n",
      "[0.994, 0.9947, 0.9947, 0.9947, 0.9934, 0.994, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "8\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "9\n",
      "[0.9947, 0.9947, 0.994, 0.994, 0.9928, 0.9947, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "9\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 1 1]\n",
      "already stored\n",
      "0.9937\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "10\n",
      "[0.9947, 0.9947, 0.9937, 0.9934, 0.9928, 0.9943, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "10\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "11\n",
      "[0.9947, 0.9947, 0.9943, 0.9943, 0.9943, 0.994, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "11\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "12\n",
      "[0.9934, 0.9928, 0.994, 0.994, 0.9947, 0.9947, 0.9928, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "12\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "[1 0 1 0 0 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.3524 - acc: 0.8846 - val_loss: 0.0626 - val_acc: 0.9800\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0790 - acc: 0.9757 - val_loss: 0.0485 - val_acc: 0.9850\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0524 - acc: 0.9830 - val_loss: 0.0277 - val_acc: 0.9907\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0411 - acc: 0.9873 - val_loss: 0.0223 - val_acc: 0.9925\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0236 - val_acc: 0.9924\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0282 - acc: 0.9910 - val_loss: 0.0216 - val_acc: 0.9931\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0216 - val_acc: 0.9931\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0229 - acc: 0.9929 - val_loss: 0.0210 - val_acc: 0.9933\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0182 - val_acc: 0.9945\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0158 - acc: 0.9951 - val_loss: 0.0228 - val_acc: 0.9936\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0220 - val_acc: 0.9930\n",
      "Test loss: 0.022003867817627906\n",
      "Test accuracy: 0.993\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 1 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.3812 - acc: 0.8763 - val_loss: 0.0640 - val_acc: 0.9782\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0820 - acc: 0.9762 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0540 - acc: 0.9832 - val_loss: 0.0262 - val_acc: 0.9919\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.0301 - val_acc: 0.9908\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0349 - acc: 0.9889 - val_loss: 0.0282 - val_acc: 0.9904\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0297 - acc: 0.9913 - val_loss: 0.0240 - val_acc: 0.9924\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0264 - acc: 0.9917 - val_loss: 0.0204 - val_acc: 0.9931\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0222 - val_acc: 0.9931\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0209 - acc: 0.9936 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0209 - val_acc: 0.9936\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0240 - val_acc: 0.9931\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0190 - val_acc: 0.9943\n",
      "Test loss: 0.0189584252256951\n",
      "Test accuracy: 0.9943\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 1 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.4340 - acc: 0.8572 - val_loss: 0.0499 - val_acc: 0.9838\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0797 - acc: 0.9772 - val_loss: 0.0394 - val_acc: 0.9873\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0522 - acc: 0.9848 - val_loss: 0.0372 - val_acc: 0.9883\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0414 - acc: 0.9883 - val_loss: 0.0350 - val_acc: 0.9882\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0321 - acc: 0.9905 - val_loss: 0.0209 - val_acc: 0.9938\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0289 - acc: 0.9914 - val_loss: 0.0203 - val_acc: 0.9941\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0241 - acc: 0.9931 - val_loss: 0.0420 - val_acc: 0.9898\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.0221 - val_acc: 0.9924\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0172 - val_acc: 0.9945\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0335 - val_acc: 0.9910\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0355 - val_acc: 0.9901\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0268 - val_acc: 0.9929\n",
      "Test loss: 0.026759528472432886\n",
      "Test accuracy: 0.9929\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      " Accuracy of populationnummer: \n",
      "13\n",
      "[0.993, 0.9947, 0.9943, 0.994, 0.994, 0.9947, 0.9929, 0.994]\n",
      "highest accuracy of populationnummer: \n",
      "13\n",
      "0.9947\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 1 0]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 1 1 0 1 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.3143 - acc: 0.8996 - val_loss: 0.0561 - val_acc: 0.9839\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0791 - acc: 0.9756 - val_loss: 0.0367 - val_acc: 0.9886\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0558 - acc: 0.9827 - val_loss: 0.0346 - val_acc: 0.9889\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0437 - acc: 0.9865 - val_loss: 0.0330 - val_acc: 0.9882 0.04\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0366 - acc: 0.9885 - val_loss: 0.0235 - val_acc: 0.9925\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0328 - acc: 0.9898 - val_loss: 0.0204 - val_acc: 0.9931\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0279 - acc: 0.9912 - val_loss: 0.0229 - val_acc: 0.9929\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0200 - val_acc: 0.9933\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0230 - acc: 0.9928 - val_loss: 0.0246 - val_acc: 0.9925\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0198 - val_acc: 0.9932\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0211 - val_acc: 0.9928\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0189 - val_acc: 0.9935\n",
      "Test loss: 0.018928314514170052\n",
      "Test accuracy: 0.9935\n",
      " Accuracy of populationnummer: \n",
      "14\n",
      "[0.9947, 0.9947, 0.994, 0.9947, 0.9943, 0.994, 0.994, 0.9935]\n",
      "highest accuracy of populationnummer: \n",
      "14\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 1 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.3186 - acc: 0.8974 - val_loss: 0.0893 - val_acc: 0.9733\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0791 - acc: 0.9766 - val_loss: 0.0437 - val_acc: 0.9849\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0544 - acc: 0.9829 - val_loss: 0.0404 - val_acc: 0.9869\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0427 - acc: 0.9870 - val_loss: 0.0286 - val_acc: 0.9909\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0357 - acc: 0.9890 - val_loss: 0.0256 - val_acc: 0.9913\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0300 - acc: 0.9910 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0267 - val_acc: 0.9910\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0211 - acc: 0.9934 - val_loss: 0.0234 - val_acc: 0.9918\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0224 - val_acc: 0.9929\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 0.0198 - val_acc: 0.9932\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0246 - val_acc: 0.9927\n",
      "Test loss: 0.02457265602884072\n",
      "Test accuracy: 0.9927\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[1 0 1 0 1 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.3046 - acc: 0.9033 - val_loss: 0.0610 - val_acc: 0.9798\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0789 - acc: 0.9761 - val_loss: 0.0439 - val_acc: 0.9852\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0561 - acc: 0.9824 - val_loss: 0.0370 - val_acc: 0.9882\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0442 - acc: 0.9860 - val_loss: 0.0255 - val_acc: 0.9918\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0369 - acc: 0.9884 - val_loss: 0.0272 - val_acc: 0.9906\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0311 - acc: 0.9905 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0276 - acc: 0.9911 - val_loss: 0.0236 - val_acc: 0.9917\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0267 - acc: 0.9917 - val_loss: 0.0221 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0278 - val_acc: 0.9917\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0312 - val_acc: 0.9900\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0188 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0183 - acc: 0.9943 - val_loss: 0.0219 - val_acc: 0.9924\n",
      "Test loss: 0.021930737041243265\n",
      "Test accuracy: 0.9924\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "15\n",
      "[0.9947, 0.9947, 0.9947, 0.9927, 0.9947, 0.9924, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "15\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[0 0 1 0 0 0]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "16\n",
      "[0.9947, 0.9947, 0.994, 0.9934, 0.994, 0.9947, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "16\n",
      "0.9947\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      " Accuracy of populationnummer: \n",
      "17\n",
      "[0.9947, 0.9947, 0.9947, 0.9947, 0.9943, 0.9947, 0.9947, 0.9947]\n",
      "highest accuracy of populationnummer: \n",
      "17\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 0 0 1 1]\n",
      "already stored\n",
      "0.9937\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      " Accuracy of populationnummer: \n",
      "18\n",
      "[0.9947, 0.9947, 0.9928, 0.9937, 0.9928, 0.994, 0.9947, 0.9934]\n",
      "highest accuracy of populationnummer: \n",
      "18\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 1 1 0 1]\n",
      "new one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.3104 - acc: 0.9004 - val_loss: 0.0589 - val_acc: 0.9811\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0722 - acc: 0.9780 - val_loss: 0.0375 - val_acc: 0.9882\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0499 - acc: 0.9848 - val_loss: 0.0349 - val_acc: 0.9884\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0390 - acc: 0.9880 - val_loss: 0.0270 - val_acc: 0.9904\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0276 - acc: 0.9914 - val_loss: 0.0245 - val_acc: 0.9923\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0233 - val_acc: 0.9925\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0221 - acc: 0.9932 - val_loss: 0.0200 - val_acc: 0.9936\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0218 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 0.0295 - val_acc: 0.9921\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 0.0190 - val_acc: 0.9945\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0158 - acc: 0.9953 - val_loss: 0.0180 - val_acc: 0.9939\n",
      "Test loss: 0.018032650895263215\n",
      "Test accuracy: 0.9939\n",
      "[1 0 0 0 0 1]\n",
      "already stored\n",
      "0.9928\n",
      "[0 0 0 0 1 1]\n",
      "already stored\n",
      "0.9937\n",
      " Accuracy of populationnummer: \n",
      "19\n",
      "[0.994, 0.9947, 0.9947, 0.9947, 0.9943, 0.9939, 0.9928, 0.9937]\n",
      "highest accuracy of populationnummer: \n",
      "19\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 0 0 0 0 1]\n",
      "already stored\n",
      "0.9947\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      "[0 0 1 0 0 1]\n",
      "already stored\n",
      "0.994\n",
      "[0 1 0 0 0 1]\n",
      "already stored\n",
      "0.9943\n",
      " Accuracy of populationnummer: \n",
      "20\n",
      "[0.9934, 0.9947, 0.9947, 0.9947, 0.9947, 0.9943, 0.994, 0.9943]\n",
      "highest accuracy of populationnummer: \n",
      "20\n",
      "0.9947\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "Muation\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "[0 0 1 0 0 0]\n",
      "Problem\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wartezeit: \n",
      "49.919657079378766\n",
      "0.8319942846563128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hauptmethode2\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DURCHGÄNGE = 20 # variable to clarify number of generations\n",
    "actualpop= initialise()\n",
    "craschcheck(actualpop)\n",
    "\n",
    "print('Aktuelle : ', actualpop)\n",
    "evalaccuris = []\n",
    "saved = actualpop #unn\n",
    "i = 1\n",
    "\n",
    "    \n",
    "while i < DURCHGÄNGE+1:\n",
    "    \n",
    "    nummer = i\n",
    "    accuri = getaccur(actualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(accuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(accuri))\n",
    "    #print(actualpop)\n",
    "    actualpop = fortpflanzung(accuri, actualpop)\n",
    "    actualpop = mutationeach(actualpop)\n",
    "    craschcheck(actualpop)\n",
    "   \n",
    "    evalaccuris.append([i , sum(accuri)/len(accuri),np.amax(accuri),actualpop[np.argmax(accuri)]])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('Wartezeit: ')\n",
    "end = time.time()\n",
    "seconds = end - start\n",
    "minutes = seconds / 60\n",
    "print(minutes)\n",
    "hours = minutes/60\n",
    "print(hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisation\n",
    "df = pd.DataFrame(data =evalaccuris)\n",
    "df.rename(columns={0: 'Generation',1: 'Accuracy Mean',2:'Accuracy Best',3: 'Best Individum'}, inplace=True)\n",
    "df\n",
    "fr =sns.regplot(x=df['Generation'],y=df['Accuracy Best'])\n",
    "plt.ylim(0.992, 0.996)\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig = fr.get_figure()\n",
    "fig.savefig('hilf22.png') #Best_Accuracies_in_Generation ( M: 0.35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item2': 2, '[0 1 1 0 1 1]': 0.9933, '[0 1 0 0 1 0]': 0.9935, '[0 0 0 1 0 1]': 0.9934, '[0 1 0 1 1 1]': 0.9932, '[1 1 0 1 0 0]': 0.9941, '[0 1 1 0 0 1]': 0.9939, '[1 0 0 0 0 1]': 0.9928, '[0 0 0 0 0 1]': 0.9947, '[0 1 0 0 1 1]': 0.9908, '[1 1 0 1 0 1]': 0.9933, '[1 0 0 1 0 1]': 0.9925, '[0 1 0 0 0 1]': 0.9943, '[0 1 1 1 0 1]': 0.9919, '[1 1 1 0 0 1]': 0.9928, '[0 0 1 0 0 1]': 0.994, '[0 0 1 0 0 0]': 0.994, '[0 0 0 0 1 1]': 0.9937, '[1 0 1 0 0 0]': 0.993, '[0 0 1 0 1 0]': 0.9943, '[0 0 0 0 1 0]': 0.9929, '[0 1 1 0 1 0]': 0.9935, '[0 0 1 0 1 1]': 0.9927, '[1 0 1 0 1 0]': 0.9924, '[0 0 1 1 0 1]': 0.9939}\n",
      "[[0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(diction)\n",
    "print(actualpop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.9934249999999999, 0.9941, array([0, 1, 0, 0, 1, 0])],\n",
       " [2, 0.99325, 0.9947, array([0, 1, 1, 1, 0, 1])],\n",
       " [3, 0.9937625, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [4, 0.9945124999999999, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [5, 0.9945125, 0.9947, array([0, 1, 0, 0, 0, 1])],\n",
       " [6, 0.99425, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [7, 0.9942875000000001, 0.9947, array([0, 0, 1, 0, 0, 1])],\n",
       " [8, 0.9943624999999999, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [9, 0.9942875, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [10, 0.994125, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [11, 0.9944624999999999, 0.9947, array([0, 0, 0, 1, 0, 1])],\n",
       " [12, 0.9938874999999999, 0.9947, array([0, 0, 1, 0, 0, 0])],\n",
       " [13, 0.9939499999999999, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [14, 0.9942375, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [15, 0.9941625000000001, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [16, 0.9943624999999999, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [17, 0.99465, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [18, 0.99385, 0.9947, array([0, 0, 1, 0, 0, 1])],\n",
       " [19, 0.9941, 0.9947, array([0, 0, 0, 0, 0, 1])],\n",
       " [20, 0.99435, 0.9947, array([0, 0, 0, 0, 0, 1])]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalaccuris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisation von dem durchschnitt der accuracy\n",
    "\n",
    "fr =sns.regplot(x=df['Generation'],y=df['Accuracy Mean'])\n",
    "\n",
    "plt.ylim(0.992, 0.996)\n",
    "\n",
    "fig = fr.get_figure()\n",
    "fig.savefig('av1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-08a3789eb3d9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-08a3789eb3d9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Generationen 20\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Generationen 20\n",
    "Individuen 8\n",
    "Gencodelänge 6\n",
    "\n",
    "Mutationen insgesamt:\n",
    "gencode doppelungen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aktuelle :  [array([0, 1, 0, 1, 1, 0]), array([0, 0, 1, 1, 1, 0]), array([0, 0, 0, 1, 0, 1]), array([1, 0, 0, 0, 1, 1]), array([1, 0, 1, 0, 1, 0]), array([0, 1, 1, 0, 0, 1]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 1, 1, 0, 0])]\n",
      "[0 1 0 1 1 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.3188 - acc: 0.8976 - val_loss: 0.0750 - val_acc: 0.9779\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0796 - acc: 0.9757 - val_loss: 0.0456 - val_acc: 0.9846\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0564 - acc: 0.9823 - val_loss: 0.0324 - val_acc: 0.9897\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0270 - val_acc: 0.9911\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0369 - acc: 0.9883 - val_loss: 0.0233 - val_acc: 0.9924\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0216 - val_acc: 0.9929\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0266 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0261 - acc: 0.9917 - val_loss: 0.0233 - val_acc: 0.9924\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0238 - acc: 0.9923 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0212 - val_acc: 0.9936\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0192 - val_acc: 0.9932\n",
      "Test loss: 0.01921013507798052\n",
      "Test accuracy: 0.9932\n",
      "[0 0 1 1 1 0]\n",
      "already stored\n",
      "0.9934\n",
      "[0 0 0 1 0 1]\n",
      "already stored\n",
      "0.9934\n",
      "[1 0 0 0 1 1]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.3031 - acc: 0.9031 - val_loss: 0.0561 - val_acc: 0.9820\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0730 - acc: 0.9769 - val_loss: 0.0338 - val_acc: 0.9890\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0490 - acc: 0.9853 - val_loss: 0.0571 - val_acc: 0.9820\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0299 - val_acc: 0.9906\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0321 - acc: 0.9903 - val_loss: 0.0286 - val_acc: 0.9913\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0274 - acc: 0.9914 - val_loss: 0.0207 - val_acc: 0.9927\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0237 - acc: 0.9924 - val_loss: 0.0208 - val_acc: 0.9942\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0190 - val_acc: 0.9942\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0171 - val_acc: 0.9943\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0225 - val_acc: 0.9935\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0154 - acc: 0.9953 - val_loss: 0.0219 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0195 - val_acc: 0.9935\n",
      "Test loss: 0.019459067858048185\n",
      "Test accuracy: 0.9935\n",
      "[1 0 1 0 1 0]\n",
      "already stored\n",
      "0.9924\n",
      "[0 1 1 0 0 1]\n",
      "already stored\n",
      "0.9939\n",
      "[0 0 0 0 1 1]\n",
      "already stored\n",
      "0.9937\n",
      "[0 1 1 1 0 0]\n",
      "new one\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.2981 - acc: 0.9044 - val_loss: 0.0606 - val_acc: 0.9811\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0817 - acc: 0.9754 - val_loss: 0.0426 - val_acc: 0.9869\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0588 - acc: 0.9822 - val_loss: 0.0305 - val_acc: 0.9895\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0468 - acc: 0.9858 - val_loss: 0.0338 - val_acc: 0.9886\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0388 - acc: 0.9879 - val_loss: 0.0279 - val_acc: 0.9906\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0344 - acc: 0.9892 - val_loss: 0.0238 - val_acc: 0.9932\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0302 - acc: 0.9907 - val_loss: 0.0287 - val_acc: 0.9908\n",
      "Epoch 8/12\n",
      " 8320/60000 [===>..........................] - ETA: 9s - loss: 0.0221 - acc: 0.9930"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hauptmethode2\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DURCHGÄNGE = 50 # variable to clarify number of generations\n",
    "aactualpop= initialise()\n",
    "craschcheck(aactualpop)\n",
    "\n",
    "print('Aktuelle : ', aactualpop)\n",
    "aevalaccuris = []\n",
    "saved = aactualpop #unn\n",
    "i = 1\n",
    "\n",
    "    \n",
    "while i < DURCHGÄNGE+1:\n",
    "    \n",
    "    nummer = i\n",
    "    aaccuri = getaccur(aactualpop)\n",
    "    print(' Accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(aaccuri)\n",
    "    print('highest accuracy of populationnummer: ')\n",
    "    print( nummer)\n",
    "    print(np.amax(aaccuri))\n",
    "    #print(actualpop)\n",
    "    aactualpop = fortpflanzung(aaccuri, aactualpop)\n",
    "    aactualpop = mutationeach(aactualpop)\n",
    "    craschcheck(aactualpop)\n",
    "   \n",
    "    aevalaccuris.append([i , sum(aaccuri)/len(aaccuri),np.amax(aaccuri),actualpop[np.argmax(aaccuri)]])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('Wartezeit: ')\n",
    "end = time.time()\n",
    "seconds = end - start\n",
    "minutes = seconds / 60\n",
    "print(minutes)\n",
    "hours = minutes/60\n",
    "print(hours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation\n",
    "dfa = pd.DataFrame(data =aevalaccuris)\n",
    "dfa.rename(columns={0: 'Generation',1: 'Accuracy Mean',2:'Accuracy Best',3: 'Best Individum'}, inplace=True)\n",
    "dfa\n",
    "fr =sns.regplot(x=dfa['Generation'],y=dfa['Accuracy Best'])\n",
    "plt.ylim(0.992, 0.996)\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig = fr.get_figure()\n",
    "fig.savefig('best fifity 0.35.png') #Best_Accuracies_in_Generation ( M: 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation von dem durchschnitt der accuracy\n",
    "\n",
    "fr =sns.regplot(x=dfa['Generation'],y=dfa['Accuracy Mean'])\n",
    "\n",
    "plt.ylim(0.992, 0.996)\n",
    "\n",
    "fig = fr.get_figure()\n",
    "fig.savefig('mean 50 0.35.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item2': 2, '[0 1 1 0 1 1]': 0.9933, '[0 1 0 0 1 0]': 0.9935, '[0 0 0 1 0 1]': 0.9934, '[0 1 0 1 1 1]': 0.9932, '[1 1 0 1 0 0]': 0.9941, '[0 1 1 0 0 1]': 0.9939, '[1 0 0 0 0 1]': 0.9928, '[0 0 0 0 0 1]': 0.9947, '[0 1 0 0 1 1]': 0.9908, '[1 1 0 1 0 1]': 0.9933, '[1 0 0 1 0 1]': 0.9925, '[0 1 0 0 0 1]': 0.9943, '[0 1 1 1 0 1]': 0.9919, '[1 1 1 0 0 1]': 0.9928, '[0 0 1 0 0 1]': 0.994, '[0 0 1 0 0 0]': 0.994, '[0 0 0 0 1 1]': 0.9937, '[1 0 1 0 0 0]': 0.993, '[0 0 1 0 1 0]': 0.9943, '[0 0 0 0 1 0]': 0.9929, '[0 1 1 0 1 0]': 0.9935, '[0 0 1 0 1 1]': 0.9927, '[1 0 1 0 1 0]': 0.9924, '[0 0 1 1 0 1]': 0.9939, '[0 0 0 1 0 0]': 0.9944, '[1 1 1 1 1 1]': 0.9859, '[0 0 0 1 1 0]': 0.994, '[1 1 1 0 0 0]': 0.994, '[1 1 1 1 0 0]': 0.993, '[0 1 0 1 0 1]': 0.9938, '[1 1 0 0 0 1]': 0.9935, '[0 1 0 0 0 0]': 0.993, '[1 1 0 1 1 0]': 0.9919, '[1 1 1 0 1 0]': 0.9937, '[1 1 0 0 1 1]': 0.9927, '[0 0 1 1 1 0]': 0.9934, '[0 1 1 0 0 0]': 0.9922, '[0 1 1 1 1 1]': 0.9916, '[1 0 1 1 0 0]': 0.9942, '[1 0 1 1 1 0]': 0.9927}\n"
     ]
    }
   ],
   "source": [
    "print(diction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aevalaccuris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"mySavedDict.txt\", \"wb\") as myFile:\n",
    "    pickle.dump(diction, myFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mySavedDict.txt\", \"rb\") as myFile:\n",
    "    myNewPulledInDictionary = pickle.load(myFile)\n",
    "\n",
    "print (myNewPulledInDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item2': 2, '[0 1 1 0 1 1]': 0.9933, '[0 1 0 0 1 0]': 0.9935, '[0 0 0 1 0 1]': 0.9934, '[0 1 0 1 1 1]': 0.9932, '[1 1 0 1 0 0]': 0.9941, '[0 1 1 0 0 1]': 0.9939, '[1 0 0 0 0 1]': 0.9928, '[0 0 0 0 0 1]': 0.9947, '[0 1 0 0 1 1]': 0.9908, '[1 1 0 1 0 1]': 0.9933, '[1 0 0 1 0 1]': 0.9925, '[0 1 0 0 0 1]': 0.9943, '[0 1 1 1 0 1]': 0.9919, '[1 1 1 0 0 1]': 0.9928, '[0 0 1 0 0 1]': 0.994, '[0 0 1 0 0 0]': 0.994, '[0 0 0 0 1 1]': 0.9937, '[1 0 1 0 0 0]': 0.993, '[0 0 1 0 1 0]': 0.9943, '[0 0 0 0 1 0]': 0.9929, '[0 1 1 0 1 0]': 0.9935, '[0 0 1 0 1 1]': 0.9927, '[1 0 1 0 1 0]': 0.9924, '[0 0 1 1 0 1]': 0.9939, '[0 0 0 1 0 0]': 0.9944, '[1 1 1 1 1 1]': 0.9859, '[0 0 0 1 1 0]': 0.994, '[1 1 1 0 0 0]': 0.994, '[1 1 1 1 0 0]': 0.993, '[0 1 0 1 0 1]': 0.9938, '[1 1 0 0 0 1]': 0.9935, '[0 1 0 0 0 0]': 0.993, '[1 1 0 1 1 0]': 0.9919, '[1 1 1 0 1 0]': 0.9937, '[1 1 0 0 1 1]': 0.9927, '[0 0 1 1 1 0]': 0.9934, '[0 1 1 0 0 0]': 0.9922, '[0 1 1 1 1 1]': 0.9916, '[1 0 1 1 0 0]': 0.9942, '[1 0 1 1 1 0]': 0.9927}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
